{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true,
    "pycharm": {
     "is_executing": false,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import math as m\n",
    "import linecache\n",
    "from collections import deque\n",
    "import csv\n",
    "import zipfile\n",
    "import threading\n",
    "import numpy as np\n",
    "import os\n",
    "import json\n",
    "import time\n",
    "from ReadersourcingToolkit import ReadersourcingToolkit\n",
    "\n",
    "# Scroll to the bottom for the samples section\n",
    "\n",
    "def readersourcing(parameters : ReadersourcingToolkit):\n",
    "    \n",
    "    # Checking parameters for weird things\n",
    "    \n",
    "    if parameters.days_serialization:\n",
    "        if parameters.days_number % parameters.days_serialization_threshold != 0:\n",
    "            raise ValueError('days_serialization_threshold must be a divider of days_number')\n",
    "        if  parameters.days_serialization_threshold < 0 or parameters.days_serialization_threshold > parameters.days_number:\n",
    "            raise ValueError('this must be correct: 0 < days_serialization_threshold <= days_number')\n",
    "        if parameters.current_day < 0 or parameters.current_day > parameters.days_number:\n",
    "            raise ValueError('this must be correct: 0 <= current_day <= days_number')\n",
    "        if parameters.days_serialization_cleaning:\n",
    "            if parameters.days_cleaning_threshold < 0 or parameters.days_cleaning_threshold > parameters.days_number:\n",
    "                raise ValueError('this must be correct: 0 < days_cleaning_threshold <= days_number')\n",
    "    if parameters.data_shuffled:\n",
    "         if parameters.current_shuffle < 0:\n",
    "             raise ValueError('this must be correct: current_shuffle >= 0')\n",
    "         if parameters.shuffle_amount < 0:\n",
    "             raise ValueError('this must be correct: shuffle_amount >= 0')\n",
    "\n",
    "    # Reader score must be set to a very small value otherwise there will be a division by 0\n",
    "    \n",
    "    epsilon = 0.000001\n",
    "    \n",
    "    # CSV file parsing\n",
    "    \n",
    "    info_filename = \"{}info.csv\".format(parameters.dataset_entries_path)\n",
    "    ratings_filename = \"{}ratings.csv\".format(parameters.dataset_entries_path)\n",
    "    authors_filename = \"{}authors.csv\".format(parameters.dataset_entries_path)\n",
    "    \n",
    "    info = pd.read_csv(info_filename)\n",
    "    paper_authors = pd.read_csv(authors_filename)\n",
    "    paper_authors = paper_authors.values\n",
    "    paper_ratings = pd.read_csv(info_filename)\n",
    "    paper_ratings = paper_ratings.values\n",
    "        \n",
    "    csv_offset = 2\n",
    "        \n",
    "    # Initial Readersourcing setup\n",
    "    \n",
    "    dataset_name = info[\"Dataset\"][0]\n",
    "    papers_number = info[\"Paper\"][0]\n",
    "    readers_number = info[\"Reader\"][0]\n",
    "    ratings_number = info[\"Rating\"][0]\n",
    "    authors_number = info[\"Author\"][0]\n",
    "    papers = np.arange(papers_number)\n",
    "    readers = np.arange(readers_number)\n",
    "    ratings = np.arange(ratings_number)\n",
    "    authors = np.arange(authors_number)\n",
    "    paper_steadiness = np.zeros(papers_number)\n",
    "    paper_score = np.zeros(papers_number)\n",
    "    rating_goodness = np.zeros(ratings_number)\n",
    "    reader_steadiness = np.zeros(readers_number)\n",
    "    reader_score = np.zeros(readers_number)\n",
    "    reader_score.fill(epsilon)\n",
    "    author_steadiness = np.zeros(authors_number)\n",
    "    author_score = np.zeros(authors_number)\n",
    "    \n",
    "    # Day serialization handling\n",
    "    \n",
    "    if parameters.days_serialization:\n",
    "        ratings_number_per_day = m.floor(int(ratings_number / parameters.days_number))\n",
    "        computed_days = 1\n",
    "        written = False\n",
    "        # cleaned = False\n",
    "        \n",
    "    # Data shuffling handling\n",
    "    \n",
    "    if parameters.data_shuffled:\n",
    "        ratings_filename = \"{}shuffle_{}.csv\".format(parameters.dataset_shuffle_path, parameters.current_shuffle)\n",
    "    \n",
    "    # Output handling\n",
    "    \n",
    "    result_file_paths = []\n",
    "    \n",
    "    # Function to retrieve the authors of a given paper\n",
    "    \n",
    "    def get_author(current_paper) :\n",
    "        \n",
    "        found_authors = []\n",
    "        \n",
    "        for author_index, author_entry in enumerate(paper_authors) :\n",
    "            current_author = int(author_entry[0])\n",
    "            written_papers = author_entry[1].split(\";\")\n",
    "            written_papers = [int(x) for x in written_papers]\n",
    "            if current_paper in written_papers :\n",
    "                found_authors.append(current_author)\n",
    "                \n",
    "        return np.asarray(found_authors)\n",
    "    \n",
    "    # Function to output result to file\n",
    "    \n",
    "    def serialize_result(current_index, verbose, parameters):\n",
    "                         \n",
    "        if parameters.data_shuffled:\n",
    "            result_folder_path = \"{}shuffle_{}/\".format(parameters.result_shuffle_base_path, parameters.current_shuffle)\n",
    "        else:\n",
    "            if parameters.days_serialization:\n",
    "                result_folder_path = \"{}day_{}/\".format(parameters.result_days_path, parameters.current_day)\n",
    "            else:\n",
    "                result_folder_path = parameters.result_folder_base_path\n",
    "        \n",
    "        os.makedirs(result_folder_path, exist_ok=True)\n",
    "    \n",
    "        # Quantities output handling\n",
    "    \n",
    "        dictionary = [\n",
    "            {'Quantity': 'Paper Steadiness', 'Identifiers': papers.tolist(), 'Values': paper_steadiness.tolist()},\n",
    "            {'Quantity': 'Paper Score', 'Identifiers': papers.tolist(), 'Values': paper_score.tolist()},\n",
    "            {'Quantity': 'Reader Steadiness', 'Identifiers': readers.tolist(), 'Values': reader_steadiness.tolist()},\n",
    "            {'Quantity': 'Reader Score', 'Identifiers': readers.tolist(), 'Values': reader_score.tolist()},\n",
    "            {'Quantity': 'Author Steadiness', 'Identifiers': authors.tolist(), 'Values': author_steadiness.tolist()},\n",
    "            {'Quantity': 'Author Score', 'Identifiers': authors.tolist(), 'Values': author_score.tolist()},\n",
    "        ]\n",
    "        \n",
    "        result_quantities_filename = \"{}quantities.json\".format(result_folder_path, parameters.current_day)\n",
    "        \n",
    "        if verbose:\n",
    "            print(\"------------------------------\")\n",
    "            print(\"PRINTING QUANTITIES TO .JSON FILE AT PATH {}\".format(result_quantities_filename))\n",
    "        \n",
    "        with open(result_quantities_filename, 'w') as result_quantities_file:  \n",
    "            json.dump(dictionary, result_quantities_file)\n",
    "        result_quantities_file.close()\n",
    "            \n",
    "        # Rating and goodness matrix output handling\n",
    "        \n",
    "        rating_matrix = np.zeros((readers_number, papers_number))\n",
    "        goodness_matrix = np.zeros((readers_number, papers_number))\n",
    "                \n",
    "        for rating_index in range(csv_offset, csv_offset + current_index):\n",
    "                    \n",
    "            current_entry = linecache.getline(ratings_filename, rating_index).split(\",\")\n",
    "                                \n",
    "            # Example: <1,1,2,0.8,0>\n",
    "            # At Timestamp 1 Reader 1 gave to Paper 2 a Rating of 0.8\n",
    "            current_timestamp = int(current_entry[0])\n",
    "            current_reader = int(current_entry[1])\n",
    "            current_paper = int(current_entry[2])\n",
    "            current_rating = float(current_entry[3])\n",
    "                \n",
    "            rating_matrix[current_reader][current_paper] = current_rating\n",
    "            goodness_matrix[current_reader][current_paper] = rating_goodness[current_timestamp]\n",
    "        \n",
    "        result_ratings_filename = \"{}ratings.csv\".format(result_folder_path, parameters.current_day)\n",
    "        result_goodness_filename = \"{}goodness.csv\".format(result_folder_path, parameters.current_day)\n",
    "        \n",
    "        if verbose:\n",
    "            print(\"PRINTING RATING MATRIX TO .CSV FILE AT PATH {}\".format(result_ratings_filename))\n",
    "                \n",
    "        paper_ratings_dataframe = pd.read_csv(ratings_filename)\n",
    "        ratings_matrix = paper_ratings_dataframe.pivot_table(index=\"Reader\", columns=\"Paper\", values=\"Score\")\n",
    "        ratings_matrix.fillna(0, inplace=True)\n",
    "        ratings_matrix.to_csv(result_ratings_filename, sep=\",\", header=False, index=False)\n",
    "        \n",
    "        with open(result_ratings_filename, mode='w', newline='') as result_ratings_file:\n",
    "            ratings_writer = csv.writer(result_ratings_file, delimiter=',', quotechar='\"', quoting=csv.QUOTE_MINIMAL)\n",
    "            for rating_entry in rating_matrix:\n",
    "                ratings_writer.writerow(rating_entry)\n",
    "        result_ratings_file.close()\n",
    "            \n",
    "        if verbose:\n",
    "            print(\"PRINTING RATING GOODNESS MATRIX TO .CSV FILE AT PATH {}\".format(result_goodness_filename))\n",
    "        \n",
    "        with open(result_goodness_filename, mode='w', newline='') as result_goodness_file:\n",
    "            goodness_writer = csv.writer(result_goodness_file, delimiter=',', quotechar='\"', quoting=csv.QUOTE_MINIMAL)\n",
    "            for goodness_entry in goodness_matrix:\n",
    "                goodness_writer.writerow(goodness_entry)\n",
    "        result_goodness_file.close()\n",
    "        \n",
    "        # Info output handling\n",
    "        \n",
    "        result_elapsed_time = time.time() - start_time \n",
    "        \n",
    "        dictionary = [{'Time': result_elapsed_time}]\n",
    "        \n",
    "        result_info_filename = \"{}info.json\".format(result_folder_path, parameters.current_day)\n",
    "        \n",
    "        if verbose:\n",
    "            print(\"PRINTING INFO TO .JSON FILE AT PATH {}\".format(result_info_filename))\n",
    "            print(\"------------------------------\")\n",
    "            \n",
    "        with open(result_info_filename, 'w') as result_info_file:  \n",
    "            json.dump(dictionary, result_info_file)\n",
    "        result_info_file.close()\n",
    "        \n",
    "        if parameters.result_compression:\n",
    "            print(\"--------------------------------------\")\n",
    "            print(\"---------- COMPRESSING RESULTS ----------\")\n",
    "            archive_filename = \"{}{}.zip\".format(result_folder_path, parameters.archive_name)\n",
    "            archive_file = zipfile.ZipFile(archive_filename, 'w')\n",
    "            for folder, subfolders, files in os.walk(result_folder_path):\n",
    "                for file in files:\n",
    "                    if file.endswith('.csv') or file.endswith('.json'):\n",
    "                        archive_file.write(os.path.join(folder, file), os.path.relpath(os.path.join(folder,file), result_folder_path), compress_type = zipfile.ZIP_DEFLATED)\n",
    "                        thread = threading.Thread(\n",
    "                            target=os.remove,\n",
    "                            args=[os.path.relpath(os.path.join(folder,file))]\n",
    "                        )\n",
    "                        thread.daemon = True\n",
    "                        thread.start()\n",
    "            archive_file.close()           \n",
    "            print(\"RESULT COMPRESSED INTO A .ZIP ARCHIVE AT PATH {}\".format(archive_filename))\n",
    "            print(\"--------------------------------------\")\n",
    "            \n",
    "        file_paths = [result_ratings_filename, result_goodness_filename, result_quantities_filename, result_info_filename]\n",
    "        \n",
    "        return result_elapsed_time, file_paths\n",
    "    \n",
    "    # Function to clean unwanted results\n",
    "    \n",
    "    def clean_results(results_to_clean):\n",
    "        print(\"--------------------------------------\")\n",
    "        print(\"---------- CLEANING RESULTS ----------\")\n",
    "        for file_path in results_to_clean:\n",
    "            if os.path.isfile(file_path):\n",
    "                print(\"Deleting file at path: \", file_path)\n",
    "                thread = threading.Thread(\n",
    "                    target=os.remove,\n",
    "                    args=[file_path],\n",
    "                )\n",
    "                thread.daemon = True\n",
    "                thread.start()\n",
    "        print(\"--------------------------------------\")\n",
    "    \n",
    "    # There are many \"print\" that you can uncomment if you have to do some debugging\n",
    "    # print(\"##########\")\n",
    "        \n",
    "    start_time = time.time()\n",
    "    \n",
    "    for index in range(csv_offset, (ratings_number + csv_offset)):\n",
    "        \n",
    "        if parameters.days_serialization:\n",
    "            if index % (ratings_number_per_day * computed_days) == 0:\n",
    "                parameters.current_day = computed_days\n",
    "                written = False\n",
    "                cleaned = False\n",
    "                if parameters.days_serialization_cleaning and computed_days % parameters.days_cleaning_threshold == 0 and not cleaned:\n",
    "                     clean_results(result_file_paths)\n",
    "                     result_file_paths = []\n",
    "                     cleaned = True\n",
    "                if computed_days % parameters.days_serialization_threshold == 0 and not written:\n",
    "                    print(\"---------- DAY {}/{} ----------\".format(parameters.current_day, parameters.days_number))\n",
    "                    elapsed_time, paths = serialize_result(index, verbose=False, parameters=parameters)\n",
    "                    result_file_paths = result_file_paths + paths\n",
    "                    written = True\n",
    "                computed_days += 1\n",
    "                \n",
    "        percentage = 100*index/ratings_number\n",
    "        if percentage % 5 == 0:\n",
    "            print(\"{}/{} ({}/100%)\".format(int(index), ratings_number, int(percentage)))\n",
    "                    \n",
    "        entry = linecache.getline(ratings_filename, index).split(\",\")\n",
    "        \n",
    "        # Example: <1,1,2,0.8,0>\n",
    "        # At Timestamp 1 Reader 1 gave to Paper 2 a Rating of 0.8\n",
    "        timestamp = int(entry[0])\n",
    "        reader = int(entry[1])\n",
    "        paper = int(entry[2])\n",
    "        rating = float(entry[3])\n",
    "        authors_of_paper = get_author(paper)\n",
    "        \n",
    "        # print(\"---------- CURRENT ENTRY ----------\")\n",
    "        # print(f\"TIMESTAMP {timestamp} - READER {reader} - PAPER {paper} - SCORE {rating}\")\n",
    "    \n",
    "        # COMPUTATION START: PAPER AND READER SCORE\n",
    "    \n",
    "        # Saving values at time t(i)\n",
    "    \n",
    "        old_paper_steadiness = paper_steadiness[paper]\n",
    "        old_paper_score = paper_score[paper]\n",
    "        old_reader_steadiness = reader_steadiness[reader]\n",
    "        old_rating_goodness = rating_goodness[timestamp]\n",
    "        old_reader_score = reader_score[reader]\n",
    "        \n",
    "        # print(\"---------- PRINTING VALUES AT TIME T(I) ----------\")\n",
    "        # print(\"PAPER STEADINESS T(I) \", old_paper_steadiness)\n",
    "        # print(\"PAPER SCORE T(I) \", old_paper_score)\n",
    "        # print(\"READER STEADINESS T(I) \", old_paper_score)\n",
    "        # print(\"RATING GOODNESS T(I) \", rating_goodness[timestamp])\n",
    "        # print(\"READER SCORE T(I) \", old_reader_score)\n",
    "    \n",
    "        # Updating values at time t(i+1)\n",
    "    \n",
    "        paper_steadiness[paper] = old_paper_steadiness + old_reader_score\n",
    "        paper_score[paper] = ((old_paper_steadiness * old_paper_score) + (old_reader_score * rating)) / paper_steadiness[paper]\n",
    "        rating_goodness[timestamp] = (1 - (m.sqrt(abs(rating - paper_score[paper]))))\n",
    "        reader_steadiness[reader] = (old_reader_steadiness + paper_steadiness[paper])\n",
    "        reader_score[reader] = (((old_reader_steadiness * old_reader_score) + (paper_steadiness[paper] * rating_goodness[timestamp])) / reader_steadiness[reader])\n",
    "    \n",
    "        # print(\"---------- PRINTING VALUES AT TIME T(I+1) ----------\")\n",
    "        # print(\"PAPER STEADINESS T(I+1) \", paper_steadiness[paper])\n",
    "        # print(\"PAPER SCORE T(I+1) \", paper_score[paper])\n",
    "        # print(\"READER STEADINESS T(I+1) \", reader_steadiness[reader])\n",
    "        # print(\"RATING GOODNESS T(I+1) \", rating_goodness[timestamp])\n",
    "        # print(\"READER SCORE T(I+1) \", reader_score[reader])\n",
    "    \n",
    "        # COMPUTATION START: AUTHOR SCORE\n",
    "    \n",
    "        for author in authors_of_paper :\n",
    "            # Saving values at time t(i)\n",
    "    \n",
    "            old_author_steadiness = author_steadiness[author]\n",
    "            old_author_score = author_score[author]\n",
    "    \n",
    "            # Updating values at time t(i+1)7\n",
    "    \n",
    "            author_steadiness[author] = old_author_steadiness + old_reader_score\n",
    "            author_score[author] = ((old_author_steadiness * old_author_score) + (old_reader_score * rating)) / author_steadiness[author]\n",
    "    \n",
    "        # COMPUTATION START: PROPAGATING CHANGES TO PREVIOUS READERS\n",
    "            \n",
    "        previous_ratings = []        \n",
    "        with open(ratings_filename) as rating_file:\n",
    "            raw_previous_ratings = deque([next(rating_file) for x in range(csv_offset, (index + csv_offset))])\n",
    "            raw_previous_ratings.popleft()\n",
    "        rating_file.close()\n",
    "        for raw_previous_rating in raw_previous_ratings:\n",
    "            splitted_raw_previous_rating = raw_previous_rating.split(\",\")\n",
    "            if len(splitted_raw_previous_rating) > 4:\n",
    "                previous_rating = splitted_raw_previous_rating[:-1]\n",
    "            else: \n",
    "                previous_rating = splitted_raw_previous_rating\n",
    "            previous_ratings.append(previous_rating)\n",
    "        previous_ratings = np.array(previous_ratings, dtype=float)\n",
    "        previous_ratings = previous_ratings[\n",
    "             (previous_ratings[:,1]!=float(reader)) &\n",
    "             (previous_ratings[:,2]==float(paper))\n",
    "        ]            \n",
    "                       \n",
    "        # print(\" ----- PREVIOUS PAPER RATINGS -----\")\n",
    "    \n",
    "        for previous_index, previous_entry in enumerate(previous_ratings):\n",
    "                        \n",
    "            # Example: <1,1,2,0.8,0>\n",
    "            # At Timestamp 1 Reader 1 gave to Paper 2 a Rating of 0.8 written by Author 0\n",
    "            previous_timestamp = int(previous_entry[0])\n",
    "            previous_reader = int(previous_entry[1])\n",
    "            previous_paper = int(previous_entry[2])\n",
    "            previous_rating = previous_entry[3]\n",
    "    \n",
    "            # print(f\"PREVIOUS TIMESTAMP {previous_timestamp} - PREVIOUS READER {previous_reader} - PREVIOUS PAPER {previous_paper} - PREVIOUS RATING {previous_rating}\")\n",
    "    \n",
    "            # Saving previous values at time t(i)\n",
    "    \n",
    "            old_previous_reader_steadiness = reader_steadiness[previous_reader]\n",
    "            old_previous_reader_score = reader_score[previous_reader]\n",
    "            old_previous_rating = previous_rating\n",
    "            old_previous_rating_goodness = rating_goodness[previous_timestamp]\n",
    "    \n",
    "            # Updating previous values at time t(i+1)\n",
    "    \n",
    "            rating_goodness[previous_timestamp] = 1 - (m.sqrt(abs(old_previous_rating - paper_score[paper])))\n",
    "            reader_steadiness[previous_reader] = (old_previous_reader_steadiness + old_reader_score)\n",
    "            reader_score[previous_reader] = (\n",
    "                                                (old_previous_reader_steadiness * old_previous_reader_score) -\n",
    "                                                (old_paper_steadiness * old_previous_rating_goodness) +\n",
    "                                                (paper_steadiness[paper] * rating_goodness[previous_timestamp])\n",
    "                                            ) / reader_steadiness[previous_reader]\n",
    "               \n",
    "        # print(\" ----- PREVIOUS PAPER RATINGS END -----\")\n",
    "            \n",
    "        # print(\"---------- PRINTING FINAL VALUES AT TIME T(I+1) ----------\")\n",
    "        # print(\"PAPER STEADINESS: \", paper_steadiness)\n",
    "        # print(\"PAPER SCORE: \", paper_score)\n",
    "        # print(\"READER STEADINESS: \", reader_steadiness)\n",
    "        # print(\"READER SCORE: \", reader_score)\n",
    "        # print(\"##########\")\n",
    "    \n",
    "    elapsed_time, result_file_paths = serialize_result(ratings_number, verbose=True, parameters=parameters)\n",
    "    print(\"ELAPSED TIME: \", elapsed_time)\n",
    "    \n",
    "    # ----- ALGORITHM ENDS HERE ----- #\n",
    "    \n",
    "    # Summary\n",
    "    \n",
    "    #print(\"PAPER STEADINESS:  \", paper_steadiness)\n",
    "    #print(\"PAPER SCORE:       \", paper_score)\n",
    "    #print(\"READER STEADINESS: \", reader_steadiness)\n",
    "    #print(\"READER SCORE:      \", reader_score)\n",
    "    #print(\"AUTHOR STEADINESS: \", author_steadiness)\n",
    "    #print(\"AUTHOR SCORE:      \", author_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [
    {
     "name": "stdout",
     "text": [
      "3/6 (50/100%)\n6/6 (100/100%)\n------------------------------\nPRINTING QUANTITIES TO .JSON FILE AT PATH ../models/ground_truth_2/readersourcing/quantities.json\nPRINTING RATING MATRIX TO .CSV FILE AT PATH ../models/ground_truth_2/readersourcing/ratings.csv\nPRINTING RATING GOODNESS MATRIX TO .CSV FILE AT PATH ../models/ground_truth_2/readersourcing/goodness.csv\nPRINTING INFO TO .JSON FILE AT PATH ../models/ground_truth_2/readersourcing/info.json\n------------------------------\nELAPSED TIME:  0.08099937438964844\n"
     ],
     "output_type": "stream"
    }
   ],
   "source": [
    "# Samples\n",
    "\n",
    "# ------------------------------\n",
    "# ---------- SAMPLE 1 ----------\n",
    "# ------------------------------\n",
    "\n",
    "seed = ReadersourcingToolkit(\n",
    "   dataset_name=\"ground_truth_2\", \n",
    "   dataset_folder_path=\"../data/{}/\",\n",
    ")\n",
    "try:\n",
    "   readersourcing(seed)\n",
    "except ValueError as error:\n",
    "     print(repr(error))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [
    {
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-6-e83522105eee>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     12\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     13\u001b[0m \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 14\u001b[1;33m    \u001b[0mreadersourcing\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mseed\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     15\u001b[0m \u001b[1;32mexcept\u001b[0m \u001b[0mValueError\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0merror\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     16\u001b[0m     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrepr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0merror\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-4-706b5238948d>\u001b[0m in \u001b[0;36mreadersourcing\u001b[1;34m(parameters)\u001b[0m\n\u001b[0;32m    341\u001b[0m         previous_ratings = previous_ratings[\n\u001b[0;32m    342\u001b[0m              \u001b[1;33m(\u001b[0m\u001b[0mprevious_ratings\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m!=\u001b[0m\u001b[0mfloat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mreader\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m&\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 343\u001b[1;33m              \u001b[1;33m(\u001b[0m\u001b[0mprevious_ratings\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m==\u001b[0m\u001b[0mfloat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpaper\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    344\u001b[0m         ]            \n\u001b[0;32m    345\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ],
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error"
    }
   ],
   "source": [
    "# ------------------------------\n",
    "# ---------- SAMPLE 2 ----------\n",
    "# ------------------------------\n",
    "\n",
    "seed = ReadersourcingToolkit(\n",
    "    dataset_name=\"seed_1/p_1_beta\", \n",
    "    dataset_folder_path=\"../data/{}/\", \n",
    "    days_serialization=True,\n",
    "    days_number=30,\n",
    "    days_serialization_threshold=5,\n",
    ")\n",
    "   \n",
    "try:\n",
    "   readersourcing(seed)\n",
    "except ValueError as error:\n",
    "    print(repr(error))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%$\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# ------------------------------\n",
    "# ---------- SAMPLE 3 ----------\n",
    "# ------------------------------\n",
    "\n",
    "seed = ReadersourcingToolkit(\n",
    "    dataset_name=\"seed_1/p_1_beta\", \n",
    "    dataset_folder_path=\"../data/{}/\", \n",
    ")\n",
    "try:\n",
    "   readersourcing(seed)\n",
    "except ValueError as error:\n",
    "    print(repr(error))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    " \n",
    "# ------------------------------\n",
    "# ---------- SAMPLE 4 ----------\n",
    "# ------------------------------\n",
    "\n",
    "seed = ReadersourcingToolkit(\n",
    "     dataset_name=\"seed\", \n",
    "     dataset_folder_path=\"../data/{}/\", \n",
    "     data_shuffled=True, \n",
    "     current_shuffle = 0,\n",
    "     shuffle_amount=100\n",
    ")\n",
    "  \n",
    "try:\n",
    "    for index_shuffle in range(seed.shuffle_amount):\n",
    "        print(\"---------------------------------\")\n",
    "        print(\"----------- SHUFFLE {} -----------\".format(index_shuffle))\n",
    "        seed.current_shuffle = index_shuffle\n",
    "        readersourcing(seed)\n",
    "except ValueError as error:\n",
    "    print(repr(error))\n",
    "    "
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [
    {
     "name": "stdout",
     "text": [
      "---------------------------------\n----------- SHUFFLE 0 -----------\n",
      "509/10180 (5/100%)\n",
      "1018/10180 (10/100%)\n",
      "1527/10180 (15/100%)\n",
      "2036/10180 (20/100%)\n",
      "2545/10180 (25/100%)\n",
      "3054/10180 (30/100%)\n",
      "3563/10180 (35/100%)\n",
      "4072/10180 (40/100%)\n",
      "4581/10180 (45/100%)\n",
      "5090/10180 (50/100%)\n",
      "5599/10180 (55/100%)\n",
      "6108/10180 (60/100%)\n",
      "6617/10180 (65/100%)\n",
      "7126/10180 (70/100%)\n",
      "7635/10180 (75/100%)\n",
      "8144/10180 (80/100%)\n",
      "8653/10180 (85/100%)\n",
      "9162/10180 (90/100%)\n",
      "9671/10180 (95/100%)\n",
      "10180/10180 (100/100%)\n------------------------------\nPRINTING QUANTITIES TO .JSON FILE AT PATH ../models/seed_shuffle_1_special/readersourcing/shuffle/shuffle_0/quantities.json\nPRINTING RATING MATRIX TO .CSV FILE AT PATH ../models/seed_shuffle_1_special/readersourcing/shuffle/shuffle_0/ratings.csv\n",
      "PRINTING RATING GOODNESS MATRIX TO .CSV FILE AT PATH ../models/seed_shuffle_1_special/readersourcing/shuffle/shuffle_0/goodness.csv\n",
      "PRINTING INFO TO .JSON FILE AT PATH ../models/seed_shuffle_1_special/readersourcing/shuffle/shuffle_0/info.json\n------------------------------\nELAPSED TIME:  149.08925890922546\n---------------------------------\n----------- SHUFFLE 1 -----------\n",
      "509/10180 (5/100%)\n",
      "1018/10180 (10/100%)\n",
      "1527/10180 (15/100%)\n",
      "2036/10180 (20/100%)\n",
      "2545/10180 (25/100%)\n",
      "3054/10180 (30/100%)\n",
      "3563/10180 (35/100%)\n",
      "4072/10180 (40/100%)\n",
      "4581/10180 (45/100%)\n",
      "5090/10180 (50/100%)\n",
      "5599/10180 (55/100%)\n",
      "6108/10180 (60/100%)\n",
      "6617/10180 (65/100%)\n",
      "7126/10180 (70/100%)\n",
      "7635/10180 (75/100%)\n",
      "8144/10180 (80/100%)\n",
      "8653/10180 (85/100%)\n",
      "9162/10180 (90/100%)\n",
      "9671/10180 (95/100%)\n",
      "10180/10180 (100/100%)\n------------------------------\nPRINTING QUANTITIES TO .JSON FILE AT PATH ../models/seed_shuffle_1_special/readersourcing/shuffle/shuffle_1/quantities.json\nPRINTING RATING MATRIX TO .CSV FILE AT PATH ../models/seed_shuffle_1_special/readersourcing/shuffle/shuffle_1/ratings.csv\n",
      "PRINTING RATING GOODNESS MATRIX TO .CSV FILE AT PATH ../models/seed_shuffle_1_special/readersourcing/shuffle/shuffle_1/goodness.csv\n",
      "PRINTING INFO TO .JSON FILE AT PATH ../models/seed_shuffle_1_special/readersourcing/shuffle/shuffle_1/info.json\n------------------------------\nELAPSED TIME:  147.86722350120544\n---------------------------------\n----------- SHUFFLE 2 -----------\n",
      "509/10180 (5/100%)\n",
      "1018/10180 (10/100%)\n",
      "1527/10180 (15/100%)\n",
      "2036/10180 (20/100%)\n",
      "2545/10180 (25/100%)\n",
      "3054/10180 (30/100%)\n",
      "3563/10180 (35/100%)\n",
      "4072/10180 (40/100%)\n",
      "4581/10180 (45/100%)\n",
      "5090/10180 (50/100%)\n",
      "5599/10180 (55/100%)\n",
      "6108/10180 (60/100%)\n",
      "6617/10180 (65/100%)\n",
      "7126/10180 (70/100%)\n",
      "7635/10180 (75/100%)\n",
      "8144/10180 (80/100%)\n",
      "8653/10180 (85/100%)\n",
      "9162/10180 (90/100%)\n",
      "9671/10180 (95/100%)\n",
      "10180/10180 (100/100%)\n------------------------------\nPRINTING QUANTITIES TO .JSON FILE AT PATH ../models/seed_shuffle_1_special/readersourcing/shuffle/shuffle_2/quantities.json\nPRINTING RATING MATRIX TO .CSV FILE AT PATH ../models/seed_shuffle_1_special/readersourcing/shuffle/shuffle_2/ratings.csv\n",
      "PRINTING RATING GOODNESS MATRIX TO .CSV FILE AT PATH ../models/seed_shuffle_1_special/readersourcing/shuffle/shuffle_2/goodness.csv\n",
      "PRINTING INFO TO .JSON FILE AT PATH ../models/seed_shuffle_1_special/readersourcing/shuffle/shuffle_2/info.json\n------------------------------\nELAPSED TIME:  146.58700251579285\n---------------------------------\n----------- SHUFFLE 3 -----------\n",
      "509/10180 (5/100%)\n",
      "1018/10180 (10/100%)\n",
      "1527/10180 (15/100%)\n",
      "2036/10180 (20/100%)\n",
      "2545/10180 (25/100%)\n",
      "3054/10180 (30/100%)\n",
      "3563/10180 (35/100%)\n",
      "4072/10180 (40/100%)\n",
      "4581/10180 (45/100%)\n",
      "5090/10180 (50/100%)\n",
      "5599/10180 (55/100%)\n",
      "6108/10180 (60/100%)\n",
      "6617/10180 (65/100%)\n",
      "7126/10180 (70/100%)\n",
      "7635/10180 (75/100%)\n",
      "8144/10180 (80/100%)\n",
      "8653/10180 (85/100%)\n",
      "9162/10180 (90/100%)\n",
      "9671/10180 (95/100%)\n",
      "10180/10180 (100/100%)\n------------------------------\nPRINTING QUANTITIES TO .JSON FILE AT PATH ../models/seed_shuffle_1_special/readersourcing/shuffle/shuffle_3/quantities.json\nPRINTING RATING MATRIX TO .CSV FILE AT PATH ../models/seed_shuffle_1_special/readersourcing/shuffle/shuffle_3/ratings.csv\n",
      "PRINTING RATING GOODNESS MATRIX TO .CSV FILE AT PATH ../models/seed_shuffle_1_special/readersourcing/shuffle/shuffle_3/goodness.csv\n",
      "PRINTING INFO TO .JSON FILE AT PATH ../models/seed_shuffle_1_special/readersourcing/shuffle/shuffle_3/info.json\n------------------------------\nELAPSED TIME:  148.07200074195862\n"
     ],
     "output_type": "stream"
    }
   ],
   "source": [
    "# ------------------------------\n",
    "# ---------- SAMPLE 5 ----------\n",
    "# ------------------------------\n",
    "\n",
    "seed = ReadersourcingToolkit(\n",
    "     dataset_name=\"seed_shuffle_1_special\", \n",
    "     dataset_folder_path=\"../data/{}/\", \n",
    "     data_shuffled=True, \n",
    "     current_shuffle = 0,\n",
    "     shuffle_amount=100\n",
    ")\n",
    "  \n",
    "try:\n",
    "    for index_shuffle in range(seed.shuffle_amount):\n",
    "        print(\"---------------------------------\")\n",
    "        print(\"----------- SHUFFLE {} -----------\".format(index_shuffle))\n",
    "        seed.current_shuffle = index_shuffle\n",
    "        readersourcing(seed)\n",
    "except ValueError as error:\n",
    "     print(repr(error))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# ------------------------------\n",
    "# ---------- SAMPLE 6 ----------\n",
    "# ------------------------------\n",
    "\n",
    "seed = ReadersourcingToolkit(\n",
    "    dataset_name=\"seed_power_law_1\", \n",
    "    dataset_folder_path=\"../data/{}/\", \n",
    ")\n",
    "try:\n",
    "   readersourcing(seed)\n",
    "except ValueError as error:\n",
    "    print(repr(error))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% \n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "python3",
   "language": "python",
   "display_name": "Python 3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  },
  "pycharm": {
   "stem_cell": {
    "cell_type": "raw",
    "source": [],
    "metadata": {
     "collapsed": false
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}