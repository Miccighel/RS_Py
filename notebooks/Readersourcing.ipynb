{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true,
    "pycharm": {
     "is_executing": false,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import math as m\n",
    "import linecache\n",
    "from collections import deque\n",
    "import csv\n",
    "import zipfile\n",
    "import threading\n",
    "import numpy as np\n",
    "import os\n",
    "import json\n",
    "import time\n",
    "from ReadersourcingToolkit import ReadersourcingToolkit\n",
    "\n",
    "# Scroll to the bottom for the samples section\n",
    "\n",
    "def readersourcing(parameters : ReadersourcingToolkit):\n",
    "    \n",
    "    # Checking parameters for weird things\n",
    "    \n",
    "    if parameters.days_serialization:\n",
    "        if parameters.days_number % parameters.days_serialization_threshold != 0:\n",
    "            raise ValueError('days_serialization_threshold must be a divider of days_number')\n",
    "        if  parameters.days_serialization_threshold < 0 or parameters.days_serialization_threshold > parameters.days_number:\n",
    "            raise ValueError('this must be correct: 0 < days_serialization_threshold <= days_number')\n",
    "        if parameters.current_day < 0 or parameters.current_day > parameters.days_number:\n",
    "            raise ValueError('this must be correct: 0 <= current_day <= days_number')\n",
    "        if parameters.days_serialization_cleaning:\n",
    "            if parameters.days_cleaning_threshold < 0 or parameters.days_cleaning_threshold > parameters.days_number:\n",
    "                raise ValueError('this must be correct: 0 < days_cleaning_threshold <= days_number')\n",
    "    if parameters.data_shuffled:\n",
    "         if parameters.current_shuffle < 0:\n",
    "             raise ValueError('this must be correct: current_shuffle >= 0')\n",
    "         if parameters.shuffle_amount < 0:\n",
    "             raise ValueError('this must be correct: shuffle_amount >= 0')\n",
    "\n",
    "    # Reader score must be set to a very small value otherwise there will be a division by 0\n",
    "    \n",
    "    epsilon = 0.000001\n",
    "    \n",
    "    # CSV file parsing\n",
    "    \n",
    "    ratings_filename = parameters.ratings_filename\n",
    "    info_filename = parameters.info_filename\n",
    "    authors_filename = parameters.authors_filename\n",
    "    \n",
    "    info = pd.read_csv(info_filename)\n",
    "    paper_authors = pd.read_csv(authors_filename)\n",
    "    paper_authors = paper_authors.values\n",
    "    paper_ratings = pd.read_csv(info_filename)\n",
    "    paper_ratings = paper_ratings.values\n",
    "        \n",
    "    csv_offset = 2\n",
    "        \n",
    "    # Initial Readersourcing setup\n",
    "    \n",
    "    dataset_name = info[\"Dataset\"][0]\n",
    "    papers_number = info[\"Paper\"][0]\n",
    "    readers_number = info[\"Reader\"][0]\n",
    "    ratings_number = info[\"Rating\"][0]\n",
    "    authors_number = info[\"Author\"][0]\n",
    "    papers = np.arange(papers_number)\n",
    "    readers = np.arange(readers_number)\n",
    "    ratings = np.arange(ratings_number)\n",
    "    authors = np.arange(authors_number)\n",
    "    paper_steadiness = np.zeros(papers_number)\n",
    "    paper_score = np.zeros(papers_number)\n",
    "    rating_goodness = np.zeros(ratings_number)\n",
    "    reader_steadiness = np.zeros(readers_number)\n",
    "    reader_score = np.zeros(readers_number)\n",
    "    reader_score.fill(epsilon)\n",
    "    author_steadiness = np.zeros(authors_number)\n",
    "    author_score = np.zeros(authors_number)\n",
    "    \n",
    "    # Day serialization handling\n",
    "    \n",
    "    if parameters.days_serialization:\n",
    "        ratings_number_per_day = m.floor(int(ratings_number / parameters.days_number))\n",
    "        computed_days = 1\n",
    "        written = False\n",
    "        # cleaned = False\n",
    "        \n",
    "    # Data shuffling handling\n",
    "    \n",
    "    if parameters.data_shuffled:\n",
    "        ratings_filename = \"{}{}\".format(parameters.dataset_shuffle_path, parameters.shuffle_filename)\n",
    "    \n",
    "    # Output handling\n",
    "    \n",
    "    result_file_paths = []\n",
    "    \n",
    "    # Function to retrieve the authors of a given paper\n",
    "    \n",
    "    def get_author(current_paper) :\n",
    "        \n",
    "        found_authors = []\n",
    "        \n",
    "        for author_index, author_entry in enumerate(paper_authors) :\n",
    "            current_author = int(author_entry[0])\n",
    "            written_papers = author_entry[1].split(\";\")\n",
    "            written_papers = [int(x) for x in written_papers]\n",
    "            if current_paper in written_papers :\n",
    "                found_authors.append(current_author)\n",
    "                \n",
    "        return np.asarray(found_authors)\n",
    "    \n",
    "    # Function to output result to file\n",
    "    \n",
    "    def serialize_result(current_index, verbose, parameters):\n",
    "                         \n",
    "        if parameters.data_shuffled:\n",
    "            result_folder_path = \"{}{}\".format(parameters.result_shuffle_base_path, parameters.result_shuffle_folder)\n",
    "        else:\n",
    "            if parameters.days_serialization:\n",
    "                result_folder_path = \"{}{}\".format(parameters.result_days_base_path, parameters.result_day_folder)\n",
    "            else:\n",
    "                result_folder_path = parameters.result_folder_base_path\n",
    "        \n",
    "        os.makedirs(result_folder_path, exist_ok=True)\n",
    "    \n",
    "        # Quantities output handling\n",
    "    \n",
    "        dictionary = [\n",
    "            {'Quantity': 'Paper Steadiness', 'Identifiers': papers.tolist(), 'Values': paper_steadiness.tolist()},\n",
    "            {'Quantity': 'Paper Score', 'Identifiers': papers.tolist(), 'Values': paper_score.tolist()},\n",
    "            {'Quantity': 'Reader Steadiness', 'Identifiers': readers.tolist(), 'Values': reader_steadiness.tolist()},\n",
    "            {'Quantity': 'Reader Score', 'Identifiers': readers.tolist(), 'Values': reader_score.tolist()},\n",
    "            {'Quantity': 'Author Steadiness', 'Identifiers': authors.tolist(), 'Values': author_steadiness.tolist()},\n",
    "            {'Quantity': 'Author Score', 'Identifiers': authors.tolist(), 'Values': author_score.tolist()},\n",
    "        ]\n",
    "        \n",
    "        result_quantities_filename = \"{}{}\".format(result_folder_path, parameters.result_quantities_filename)\n",
    "        \n",
    "        if verbose:\n",
    "            print(\"------------------------------\")\n",
    "            print(\"PRINTING QUANTITIES TO .JSON FILE AT PATH {}\".format(result_quantities_filename))\n",
    "        \n",
    "        with open(result_quantities_filename, 'w') as result_quantities_file:  \n",
    "            json.dump(dictionary, result_quantities_file)\n",
    "        result_quantities_file.close()\n",
    "            \n",
    "        # Rating and goodness matrix output handling\n",
    "        \n",
    "        rating_matrix = np.zeros((readers_number, papers_number))\n",
    "        goodness_matrix = np.zeros((readers_number, papers_number))\n",
    "                \n",
    "        for rating_index in range(csv_offset, csv_offset + current_index):\n",
    "                    \n",
    "            current_entry = linecache.getline(ratings_filename, rating_index).split(\",\")\n",
    "                                \n",
    "            # Example: <1,1,2,0.8,0>\n",
    "            # At Timestamp 1 Reader 1 gave to Paper 2 a Rating of 0.8\n",
    "            current_timestamp = int(current_entry[0])\n",
    "            current_reader = int(current_entry[1])\n",
    "            current_paper = int(current_entry[2])\n",
    "            current_rating = float(current_entry[3])\n",
    "                \n",
    "            rating_matrix[current_reader][current_paper] = current_rating\n",
    "            goodness_matrix[current_reader][current_paper] = rating_goodness[current_timestamp]\n",
    "        \n",
    "        result_ratings_filename = \"{}{}\".format(result_folder_path, parameters.result_ratings_filename)\n",
    "        result_goodness_filename = \"{}{}\".format(result_folder_path, parameters.result_goodness_filename)\n",
    "        \n",
    "        if verbose:\n",
    "            print(\"PRINTING RATING MATRIX TO .CSV FILE AT PATH {}\".format(result_ratings_filename))\n",
    "                \n",
    "        paper_ratings_dataframe = pd.read_csv(ratings_filename)\n",
    "        ratings_matrix = paper_ratings_dataframe.pivot_table(index=\"Reader\", columns=\"Paper\", values=\"Score\")\n",
    "        ratings_matrix.fillna(0, inplace=True)\n",
    "        ratings_matrix.to_csv(result_ratings_filename, sep=\",\", header=False, index=False)\n",
    "        \n",
    "        with open(result_ratings_filename, mode='w', newline='') as result_ratings_file:\n",
    "            ratings_writer = csv.writer(result_ratings_file, delimiter=',', quotechar='\"', quoting=csv.QUOTE_MINIMAL)\n",
    "            for rating_entry in rating_matrix:\n",
    "                ratings_writer.writerow(rating_entry)\n",
    "        result_ratings_file.close()\n",
    "            \n",
    "        if verbose:\n",
    "            print(\"PRINTING RATING GOODNESS MATRIX TO .CSV FILE AT PATH {}\".format(result_goodness_filename))\n",
    "        \n",
    "        with open(result_goodness_filename, mode='w', newline='') as result_goodness_file:\n",
    "            goodness_writer = csv.writer(result_goodness_file, delimiter=',', quotechar='\"', quoting=csv.QUOTE_MINIMAL)\n",
    "            for goodness_entry in goodness_matrix:\n",
    "                goodness_writer.writerow(goodness_entry)\n",
    "        result_goodness_file.close()\n",
    "        \n",
    "        # Info output handling\n",
    "        \n",
    "        result_elapsed_time = time.time() - start_time \n",
    "        \n",
    "        dictionary = [{'Time': result_elapsed_time}]\n",
    "        \n",
    "        result_info_filename = \"{}{}\".format(result_folder_path, parameters.result_info_filename)\n",
    "        \n",
    "        if verbose:\n",
    "            print(\"PRINTING INFO TO .JSON FILE AT PATH {}\".format(result_info_filename))\n",
    "            print(\"------------------------------\")\n",
    "            \n",
    "        with open(result_info_filename, 'w') as result_info_file:  \n",
    "            json.dump(dictionary, result_info_file)\n",
    "        result_info_file.close()\n",
    "        \n",
    "        if parameters.result_compression:\n",
    "            print(\"--------------------------------------\")\n",
    "            print(\"---------- COMPRESSING RESULTS ----------\")\n",
    "            archive_filename = \"{}{}.zip\".format(result_folder_path, parameters.archive_name)\n",
    "            archive_file = zipfile.ZipFile(archive_filename, 'w')\n",
    "            for folder, subfolders, files in os.walk(result_folder_path):\n",
    "                for file in files:\n",
    "                    if file.endswith('.csv') or file.endswith('.json'):\n",
    "                        archive_file.write(os.path.join(folder, file), os.path.relpath(os.path.join(folder,file), result_folder_path), compress_type = zipfile.ZIP_DEFLATED)\n",
    "                        thread = threading.Thread(\n",
    "                            target=os.remove,\n",
    "                            args=[os.path.relpath(os.path.join(folder,file))]\n",
    "                        )\n",
    "                        thread.daemon = True\n",
    "                        thread.start()\n",
    "            archive_file.close()           \n",
    "            print(\"RESULT COMPRESSED INTO A .ZIP ARCHIVE AT PATH {}\".format(archive_filename))\n",
    "            print(\"--------------------------------------\")\n",
    "            \n",
    "        file_paths = [result_ratings_filename, result_goodness_filename, result_quantities_filename, result_info_filename]\n",
    "        \n",
    "        return result_elapsed_time, file_paths\n",
    "    \n",
    "    # Function to clean unwanted results\n",
    "    \n",
    "    def clean_results(results_to_clean):\n",
    "        print(\"--------------------------------------\")\n",
    "        print(\"---------- CLEANING RESULTS ----------\")\n",
    "        for file_path in results_to_clean:\n",
    "            if os.path.isfile(file_path):\n",
    "                print(\"Deleting file at path: \", file_path)\n",
    "                thread = threading.Thread(\n",
    "                    target=os.remove,\n",
    "                    args=[file_path],\n",
    "                )\n",
    "                thread.daemon = True\n",
    "                thread.start()       \n",
    "        print(\"--------------------------------------\")\n",
    "    \n",
    "    # There are many \"print\" that you can uncomment if you have to do some debugging\n",
    "    # print(\"##########\")\n",
    "        \n",
    "    start_time = time.time()\n",
    "      \n",
    "    for index in range(csv_offset, (ratings_number + csv_offset)):\n",
    "        \n",
    "        if parameters.days_serialization:\n",
    "            if index % (ratings_number_per_day * computed_days) == 0:\n",
    "                parameters.current_day = computed_days\n",
    "                parameters.update_day()\n",
    "                written = False\n",
    "                cleaned = False\n",
    "                if parameters.days_serialization_cleaning and computed_days % parameters.days_cleaning_threshold == 0 and not cleaned:\n",
    "                     clean_results(result_file_paths)\n",
    "                     result_file_paths = []\n",
    "                     cleaned = True\n",
    "                if computed_days % parameters.days_serialization_threshold == 0 and not written:\n",
    "                    print(\"---------- DAY {}/{} ----------\".format(parameters.current_day, parameters.days_number))\n",
    "                    elapsed_time, paths = serialize_result(index, verbose=False, parameters=parameters)\n",
    "                    result_file_paths = result_file_paths + paths\n",
    "                    written = True\n",
    "                computed_days += 1\n",
    "                \n",
    "        percentage = 100*index/ratings_number\n",
    "        if percentage % 5 == 0:\n",
    "            print(\"{}/{} ({}/100%)\".format(int(index), ratings_number, int(percentage)))\n",
    "                        \n",
    "        entry = linecache.getline(ratings_filename, index).split(\",\")\n",
    "        \n",
    "        # Example: <1,1,2,0.8,0>\n",
    "        # At Timestamp 1 Reader 1 gave to Paper 2 a Rating of 0.8\n",
    "        timestamp = int(entry[0])\n",
    "        reader = int(entry[1])\n",
    "        paper = int(entry[2])\n",
    "        rating = float(entry[3])\n",
    "        authors_of_paper = get_author(paper)\n",
    "        \n",
    "        # print(\"---------- CURRENT ENTRY ----------\")\n",
    "        # print(f\"TIMESTAMP {timestamp} - READER {reader} - PAPER {paper} - SCORE {rating}\")\n",
    "    \n",
    "        # COMPUTATION START: PAPER AND READER SCORE\n",
    "    \n",
    "        # Saving values at time t(i)\n",
    "    \n",
    "        old_paper_steadiness = paper_steadiness[paper]\n",
    "        old_paper_score = paper_score[paper]\n",
    "        old_reader_steadiness = reader_steadiness[reader]\n",
    "        old_rating_goodness = rating_goodness[timestamp]\n",
    "        old_reader_score = reader_score[reader]\n",
    "        \n",
    "        # print(\"---------- PRINTING VALUES AT TIME T(I) ----------\")\n",
    "        # print(\"PAPER STEADINESS T(I) \", old_paper_steadiness)\n",
    "        # print(\"PAPER SCORE T(I) \", old_paper_score)\n",
    "        # print(\"READER STEADINESS T(I) \", old_paper_score)\n",
    "        # print(\"RATING GOODNESS T(I) \", rating_goodness[timestamp])\n",
    "        # print(\"READER SCORE T(I) \", old_reader_score)\n",
    "    \n",
    "        # Updating values at time t(i+1)\n",
    "    \n",
    "        paper_steadiness[paper] = old_paper_steadiness + old_reader_score\n",
    "        paper_score[paper] = ((old_paper_steadiness * old_paper_score) + (old_reader_score * rating)) / paper_steadiness[paper]\n",
    "        rating_goodness[timestamp] = (1 - (m.sqrt(abs(rating - paper_score[paper]))))\n",
    "        reader_steadiness[reader] = (old_reader_steadiness + paper_steadiness[paper])\n",
    "        reader_score[reader] = (((old_reader_steadiness * old_reader_score) + (paper_steadiness[paper] * rating_goodness[timestamp])) / reader_steadiness[reader])\n",
    "    \n",
    "        # print(\"---------- PRINTING VALUES AT TIME T(I+1) ----------\")\n",
    "        # print(\"PAPER STEADINESS T(I+1) \", paper_steadiness[paper])\n",
    "        # print(\"PAPER SCORE T(I+1) \", paper_score[paper])\n",
    "        # print(\"READER STEADINESS T(I+1) \", reader_steadiness[reader])\n",
    "        # print(\"RATING GOODNESS T(I+1) \", rating_goodness[timestamp])\n",
    "        # print(\"READER SCORE T(I+1) \", reader_score[reader])\n",
    "    \n",
    "        # COMPUTATION START: AUTHOR SCORE\n",
    "    \n",
    "        for author in authors_of_paper :\n",
    "            # Saving values at time t(i)\n",
    "    \n",
    "            old_author_steadiness = author_steadiness[author]\n",
    "            old_author_score = author_score[author]\n",
    "    \n",
    "            # Updating values at time t(i+1)7\n",
    "    \n",
    "            author_steadiness[author] = old_author_steadiness + old_reader_score\n",
    "            author_score[author] = ((old_author_steadiness * old_author_score) + (old_reader_score * rating)) / author_steadiness[author]\n",
    "    \n",
    "        # COMPUTATION START: PROPAGATING CHANGES TO PREVIOUS READERS\n",
    "            \n",
    "        previous_ratings = []        \n",
    "        with open(ratings_filename) as rating_file:\n",
    "            raw_previous_ratings = deque([next(rating_file) for x in range(csv_offset, (index + csv_offset))])\n",
    "            raw_previous_ratings.popleft()\n",
    "        rating_file.close()\n",
    "        for raw_previous_rating in raw_previous_ratings:\n",
    "            splitted_raw_previous_rating = raw_previous_rating.split(\",\")\n",
    "            if len(splitted_raw_previous_rating) > 4:\n",
    "                previous_rating = splitted_raw_previous_rating[:-1]\n",
    "            else: \n",
    "                previous_rating = splitted_raw_previous_rating\n",
    "            previous_ratings.append(previous_rating)\n",
    "        previous_ratings = np.array(previous_ratings, dtype=float)\n",
    "        previous_ratings = previous_ratings[\n",
    "             (previous_ratings[:,1]!=float(reader)) &\n",
    "             (previous_ratings[:,2]==float(paper))\n",
    "        ]            \n",
    "                       \n",
    "        # print(\" ----- PREVIOUS PAPER RATINGS -----\")\n",
    "    \n",
    "        for previous_index, previous_entry in enumerate(previous_ratings):\n",
    "                        \n",
    "            # Example: <1,1,2,0.8,0>\n",
    "            # At Timestamp 1 Reader 1 gave to Paper 2 a Rating of 0.8 written by Author 0\n",
    "            previous_timestamp = int(previous_entry[0])\n",
    "            previous_reader = int(previous_entry[1])\n",
    "            previous_paper = int(previous_entry[2])\n",
    "            previous_rating = previous_entry[3]\n",
    "    \n",
    "            # print(f\"PREVIOUS TIMESTAMP {previous_timestamp} - PREVIOUS READER {previous_reader} - PREVIOUS PAPER {previous_paper} - PREVIOUS RATING {previous_rating}\")\n",
    "    \n",
    "            # Saving previous values at time t(i)\n",
    "    \n",
    "            old_previous_reader_steadiness = reader_steadiness[previous_reader]\n",
    "            old_previous_reader_score = reader_score[previous_reader]\n",
    "            old_previous_rating = previous_rating\n",
    "            old_previous_rating_goodness = rating_goodness[previous_timestamp]\n",
    "    \n",
    "            # Updating previous values at time t(i+1)\n",
    "    \n",
    "            rating_goodness[previous_timestamp] = 1 - (m.sqrt(abs(old_previous_rating - paper_score[paper])))\n",
    "            reader_steadiness[previous_reader] = (old_previous_reader_steadiness + old_reader_score)\n",
    "            reader_score[previous_reader] = (\n",
    "                                                (old_previous_reader_steadiness * old_previous_reader_score) -\n",
    "                                                (old_paper_steadiness * old_previous_rating_goodness) +\n",
    "                                                (paper_steadiness[paper] * rating_goodness[previous_timestamp])\n",
    "                                            ) / reader_steadiness[previous_reader]\n",
    "               \n",
    "        # print(\" ----- PREVIOUS PAPER RATINGS END -----\")\n",
    "            \n",
    "        # print(\"---------- PRINTING FINAL VALUES AT TIME T(I+1) ----------\")\n",
    "        # print(\"PAPER STEADINESS: \", paper_steadiness)\n",
    "        # print(\"PAPER SCORE: \", paper_score)\n",
    "        # print(\"READER STEADINESS: \", reader_steadiness)\n",
    "        # print(\"READER SCORE: \", reader_score)\n",
    "        # print(\"##########\")\n",
    "    \n",
    "    elapsed_time, result_file_paths = serialize_result(ratings_number, verbose=True, parameters=parameters)\n",
    "    \n",
    "    if parameters.days_serialization:\n",
    "        for root, dirs, files in os.walk(parameters.result_days_base_path, topdown=False):\n",
    "                for name in dirs:\n",
    "                    try:\n",
    "                        if len(os.listdir( os.path.join(root, name) )) == 0: #check whether the directory is empty\n",
    "                            print( \"Deleting empty folder: \", os.path.join(root, name) )\n",
    "                            try:\n",
    "                                os.rmdir( os.path.join(root, name) )\n",
    "                            except:\n",
    "                                pass\n",
    "                    except:\n",
    "                        pass\n",
    "        print(\"--------------------------------------\")\n",
    "    \n",
    "    print(\"ELAPSED TIME: \", elapsed_time)\n",
    "    \n",
    "    # ----- ALGORITHM ENDS HERE ----- #\n",
    "    \n",
    "    # Summary\n",
    "    \n",
    "    #print(\"PAPER STEADINESS:  \", paper_steadiness)\n",
    "    #print(\"PAPER SCORE:       \", paper_score)\n",
    "    #print(\"READER STEADINESS: \", reader_steadiness)\n",
    "    #print(\"READER SCORE:      \", reader_score)\n",
    "    #print(\"AUTHOR STEADINESS: \", author_steadiness)\n",
    "    #print(\"AUTHOR SCORE:      \", author_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [
    {
     "name": "stdout",
     "text": [
      "3/6 (50/100%)\n6/6 (100/100%)\n------------------------------\nPRINTING QUANTITIES TO .JSON FILE AT PATH ../models/ground_truth_2/readersourcing/quantities.json\nPRINTING RATING MATRIX TO .CSV FILE AT PATH ../models/ground_truth_2/readersourcing/ratings.csv\nPRINTING RATING GOODNESS MATRIX TO .CSV FILE AT PATH ../models/ground_truth_2/readersourcing/goodness.csv\nPRINTING INFO TO .JSON FILE AT PATH ../models/ground_truth_2/readersourcing/info.json\n------------------------------\nELAPSED TIME:  0.08099937438964844\n"
     ],
     "output_type": "stream"
    }
   ],
   "source": [
    "# Samples\n",
    "\n",
    "# ------------------------------\n",
    "# ---------- SAMPLE 1 ----------\n",
    "# ------------------------------\n",
    "\n",
    "seed = ReadersourcingToolkit(\n",
    "   dataset_name=\"ground_truth_1\", \n",
    "   dataset_folder_path=\"../data/{}/\",\n",
    ")\n",
    "try:\n",
    "   readersourcing(seed)\n",
    "except ValueError as error:\n",
    "     print(repr(error))\n",
    "     "
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# ------------------------------\n",
    "# ---------- SAMPLE 2 ----------\n",
    "# ------------------------------\n",
    "\n",
    "seed = ReadersourcingToolkit(\n",
    "   dataset_name=\"ground_truth_2\", \n",
    "   dataset_folder_path=\"../data/{}/\",\n",
    ")\n",
    "try:\n",
    "   readersourcing(seed)\n",
    "except ValueError as error:\n",
    "     print(repr(error))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [
    {
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-4-937738b8bc09>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      9\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     10\u001b[0m \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 11\u001b[1;33m     \u001b[0mreadersourcing\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mseed\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     12\u001b[0m \u001b[1;32mexcept\u001b[0m \u001b[0mValueError\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0merror\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     13\u001b[0m      \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrepr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0merror\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-2-a38934e99d30>\u001b[0m in \u001b[0;36mreadersourcing\u001b[1;34m(parameters)\u001b[0m\n\u001b[0;32m    341\u001b[0m         \u001b[0mprevious_ratings\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0marray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mprevious_ratings\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mfloat\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    342\u001b[0m         previous_ratings = previous_ratings[\n\u001b[1;32m--> 343\u001b[1;33m              \u001b[1;33m(\u001b[0m\u001b[0mprevious_ratings\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m!=\u001b[0m\u001b[0mfloat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mreader\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m&\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    344\u001b[0m              \u001b[1;33m(\u001b[0m\u001b[0mprevious_ratings\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m==\u001b[0m\u001b[0mfloat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpaper\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    345\u001b[0m         ]            \n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ],
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error"
    }
   ],
   "source": [
    "# ------------------------------\n",
    "# ---------- SAMPLE 3 ----------\n",
    "# ------------------------------\n",
    "\n",
    "seed = ReadersourcingToolkit(\n",
    "    dataset_name=\"seed_power_law_1\", \n",
    "    dataset_folder_path=\"../data/{}/\", \n",
    ")\n",
    "  \n",
    "try:\n",
    "    readersourcing(seed)\n",
    "except ValueError as error:\n",
    "     print(repr(error))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [
    {
     "name": "stdout",
     "text": [
      "---------------------------------\n----------- SHUFFLE 0 -----------\n"
     ],
     "output_type": "stream"
    },
    {
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-3-1e32684c7f1e>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     16\u001b[0m         \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"----------- SHUFFLE {} -----------\"\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mindex_shuffle\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     17\u001b[0m         \u001b[0mseed\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcurrent_shuffle\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mindex_shuffle\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 18\u001b[1;33m         \u001b[0mreadersourcing\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mseed\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     19\u001b[0m \u001b[1;32mexcept\u001b[0m \u001b[0mValueError\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0merror\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     20\u001b[0m      \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrepr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0merror\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-2-e95269cc6d2f>\u001b[0m in \u001b[0;36mreadersourcing\u001b[1;34m(parameters)\u001b[0m\n\u001b[0;32m    285\u001b[0m         \u001b[0mold_paper_steadiness\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpaper_steadiness\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mpaper\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    286\u001b[0m         \u001b[0mold_paper_score\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpaper_score\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mpaper\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 287\u001b[1;33m         \u001b[0mold_reader_steadiness\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mreader_steadiness\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mreader\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    288\u001b[0m         \u001b[0mold_rating_goodness\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mrating_goodness\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mtimestamp\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    289\u001b[0m         \u001b[0mold_reader_score\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mreader_score\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mreader\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mIndexError\u001b[0m: index 2021 is out of bounds for axis 0 with size 2016"
     ],
     "ename": "IndexError",
     "evalue": "index 2021 is out of bounds for axis 0 with size 2016",
     "output_type": "error"
    }
   ],
   "source": [
    "# ------------------------------\n",
    "# ---------- SAMPLE 4 ----------\n",
    "# ------------------------------\n",
    "\n",
    "seed = ReadersourcingToolkit(\n",
    "    dataset_name=\"seed_power_law_1\", \n",
    "    dataset_folder_path=\"../data/{}/\", \n",
    "    data_shuffled=True, \n",
    "    current_shuffle = 0,\n",
    "    shuffle_amount=100\n",
    ")\n",
    "  \n",
    "try:\n",
    "    for index_shuffle in range(seed.shuffle_amount):\n",
    "        print(\"---------------------------------\")\n",
    "        print(\"----------- SHUFFLE {} -----------\".format(index_shuffle))\n",
    "        seed.update_shuffle(index_shuffle)\n",
    "        readersourcing(seed)\n",
    "except ValueError as error:\n",
    "     print(repr(error))\n",
    "     "
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [
    {
     "name": "stdout",
     "text": [
      "---------------------------------\n----------- SHUFFLE 0 -----------\n"
     ],
     "output_type": "stream"
    },
    {
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-7-1b418ab5f67d>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     17\u001b[0m         \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"----------- SHUFFLE {} -----------\"\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mindex_shuffle\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     18\u001b[0m         \u001b[0mseed\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcurrent_shuffle\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mindex_shuffle\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 19\u001b[1;33m         \u001b[0mreadersourcing\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mseed\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     20\u001b[0m \u001b[1;32mexcept\u001b[0m \u001b[0mValueError\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0merror\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     21\u001b[0m      \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrepr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0merror\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-5-a38934e99d30>\u001b[0m in \u001b[0;36mreadersourcing\u001b[1;34m(parameters)\u001b[0m\n\u001b[0;32m    328\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    329\u001b[0m         \u001b[0mprevious_ratings\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 330\u001b[1;33m         \u001b[1;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mratings_filename\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mrating_file\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    331\u001b[0m             \u001b[0mraw_previous_ratings\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdeque\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mnext\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrating_file\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcsv_offset\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mindex\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mcsv_offset\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    332\u001b[0m             \u001b[0mraw_previous_ratings\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpopleft\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Ambienti\\Anaconda3\\lib\\_bootlocale.py\u001b[0m in \u001b[0;36mgetpreferredencoding\u001b[1;34m(do_setlocale)\u001b[0m\n\u001b[0;32m      9\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     10\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0msys\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mplatform\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstartswith\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"win\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 11\u001b[1;33m     \u001b[1;32mdef\u001b[0m \u001b[0mgetpreferredencoding\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdo_setlocale\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     12\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0msys\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mflags\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mutf8_mode\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     13\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[1;34m'UTF-8'\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ],
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error"
    }
   ],
   "source": [
    "     \n",
    "# ------------------------------\n",
    "# ---------- SAMPLE 5 ----------\n",
    "# ------------------------------\n",
    "\n",
    "seed = ReadersourcingToolkit(\n",
    "    dataset_name=\"seed_power_law_1\", \n",
    "    dataset_folder_path=\"../data/{}/\", \n",
    "    data_shuffled=True, \n",
    "    current_shuffle = 0,\n",
    "    shuffle_amount=100,\n",
    "    shuffle_special=True\n",
    ")\n",
    "\n",
    "try:\n",
    "    for index_shuffle in range(seed.shuffle_amount):\n",
    "        print(\"---------------------------------\")\n",
    "        print(\"----------- SHUFFLE {} -----------\".format(index_shuffle))\n",
    "        seed.update_shuffle(index_shuffle)\n",
    "        readersourcing(seed)\n",
    "except ValueError as error:\n",
    "     print(repr(error))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "python3",
   "language": "python",
   "display_name": "Python 3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  },
  "pycharm": {
   "stem_cell": {
    "cell_type": "raw",
    "source": [],
    "metadata": {
     "collapsed": false
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}