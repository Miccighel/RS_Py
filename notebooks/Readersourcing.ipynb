{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true,
    "pycharm": {
     "is_executing": false,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import math as m\n",
    "import linecache\n",
    "from collections import deque\n",
    "import csv\n",
    "import zipfile\n",
    "import threading\n",
    "import numpy as np\n",
    "import os\n",
    "import json\n",
    "import time\n",
    "from ReadersourcingParameters import ReadersourcingParameters\n",
    "\n",
    "# Scroll to the bottom for the samples section\n",
    "\n",
    "def readersourcing(parameters : ReadersourcingParameters):\n",
    "    \n",
    "    # Checking parameters for weird things\n",
    "    \n",
    "    if parameters.days_serialization:\n",
    "        if parameters.days_number % parameters.days_serialization_threshold != 0:\n",
    "            raise ValueError('days_serialization_threshold must be a divider of days_number')\n",
    "        if  parameters.days_serialization_threshold < 0 or parameters.days_serialization_threshold > parameters.days_number:\n",
    "            raise ValueError('this must be correct: 0 < days_serialization_threshold <= days_number')\n",
    "        if parameters.current_day < 0 or parameters.current_day > parameters.days_number:\n",
    "            raise ValueError('this must be correct: 0 <= current_day <= days_number')\n",
    "        if parameters.days_serialization_cleaning:\n",
    "            if parameters.days_cleaning_threshold < 0 or parameters.days_cleaning_threshold > parameters.days_number:\n",
    "                raise ValueError('this must be correct: 0 < days_cleaning_threshold <= days_number')\n",
    "    if parameters.data_shuffled:\n",
    "         if parameters.current_shuffle < 0:\n",
    "             raise ValueError('this must be correct: current_shuffle >= 0')\n",
    "         if parameters.shuffle_amount < 0:\n",
    "             raise ValueError('this must be correct: shuffle_amount >= 0')\n",
    "        \n",
    "    # Parameters unpacking\n",
    "    \n",
    "    dataset_folder_path = parameters.dataset_folder_path\n",
    "    days_serialization = parameters.days_serialization\n",
    "    days_serialization_threshold = parameters.days_serialization_threshold\n",
    "    days_serialization_cleaning = parameters.days_serialization_cleaning\n",
    "    days_cleaning_threshold = parameters.days_cleaning_threshold\n",
    "    days_number = parameters.days_number\n",
    "    current_day = parameters.current_day\n",
    "    data_shuffled = parameters.data_shuffled\n",
    "    current_shuffle = parameters.current_shuffle\n",
    "\n",
    "    # Reader score must be set to a very small value otherwise there will be a division by 0\n",
    "    \n",
    "    epsilon = 0.000001\n",
    "    \n",
    "    # CSV file parsing\n",
    "    \n",
    "    info_filename = \"{}info.csv\".format(dataset_folder_path)\n",
    "    ratings_filename = \"{}ratings.csv\".format(dataset_folder_path)\n",
    "    authors_filename = \"{}authors.csv\".format(dataset_folder_path)\n",
    "    \n",
    "    info = pd.read_csv(info_filename)\n",
    "    paper_authors = pd.read_csv(authors_filename)\n",
    "    paper_authors = paper_authors.values\n",
    "    paper_ratings = pd.read_csv(info_filename)\n",
    "    paper_ratings = paper_ratings.values\n",
    "        \n",
    "    csv_offset = 2\n",
    "        \n",
    "    # Initial Readersourcing setup\n",
    "    \n",
    "    dataset_name = info[\"Dataset\"][0]\n",
    "    papers_number = info[\"Paper\"][0]\n",
    "    readers_number = info[\"Reader\"][0]\n",
    "    ratings_number = info[\"Rating\"][0]\n",
    "    authors_number = info[\"Author\"][0]\n",
    "    papers = np.arange(papers_number)\n",
    "    readers = np.arange(readers_number)\n",
    "    ratings = np.arange(ratings_number)\n",
    "    authors = np.arange(authors_number)\n",
    "    paper_steadiness = np.zeros(papers_number)\n",
    "    paper_score = np.zeros(papers_number)\n",
    "    rating_goodness = np.zeros(ratings_number)\n",
    "    reader_steadiness = np.zeros(readers_number)\n",
    "    reader_score = np.zeros(readers_number)\n",
    "    reader_score.fill(epsilon)\n",
    "    author_steadiness = np.zeros(authors_number)\n",
    "    author_score = np.zeros(authors_number)\n",
    "    \n",
    "    # Day serialization handling\n",
    "    \n",
    "    if days_serialization:\n",
    "        ratings_number_per_day = m.floor(int(ratings_number / days_number))\n",
    "        computed_days = 1\n",
    "        written = False\n",
    "        # cleaned = False\n",
    "        \n",
    "    # Data shuffling handling\n",
    "    \n",
    "    if data_shuffled:\n",
    "        ratings_filename = \"{}shuffle/shuffle_{}.csv\".format(dataset_folder_path, current_shuffle)\n",
    "    \n",
    "    # Output handling\n",
    "    \n",
    "    result_file_paths = []\n",
    "    \n",
    "    # Function to retrieve the authors of a given paper\n",
    "    \n",
    "    def get_author(current_paper) :\n",
    "        \n",
    "        found_authors = []\n",
    "        \n",
    "        for author_index, author_entry in enumerate(paper_authors) :\n",
    "            current_author = int(author_entry[0])\n",
    "            written_papers = author_entry[1].split(\";\")\n",
    "            written_papers = [int(x) for x in written_papers]\n",
    "            if current_paper in written_papers :\n",
    "                found_authors.append(current_author)\n",
    "                \n",
    "        return np.asarray(found_authors)\n",
    "    \n",
    "    # Function to output result to file\n",
    "    \n",
    "    def serialize_result(current_index, verbose, parameters):\n",
    "        \n",
    "        # Parameters  unpacking\n",
    "        \n",
    "        days_serialization = parameters.days_serialization\n",
    "        current_day = parameters.current_day\n",
    "        data_shuffled = parameters.data_shuffled\n",
    "        current_shuffle = parameters.current_shuffle\n",
    "        result_compression = parameters.result_compression\n",
    "        archive_name =  parameters.archive_name\n",
    "        result_folder_base_path = parameters.result_folder_base_path \n",
    "                         \n",
    "        if data_shuffled:\n",
    "            result_folder_path = \"../models/{}/readersourcing/shuffle/shuffle_{}/\".format(dataset_name, current_shuffle)\n",
    "        else:\n",
    "            if days_serialization:\n",
    "                result_folder_path = \"{}day_{}/\".format(result_folder_base_path, current_day)\n",
    "            else:\n",
    "                result_folder_path = result_folder_base_path\n",
    "        \n",
    "        os.makedirs(result_folder_path, exist_ok=True)\n",
    "    \n",
    "        # Quantities output handling\n",
    "    \n",
    "        dictionary = [\n",
    "            {'Quantity': 'Paper Steadiness', 'Identifiers': papers.tolist(), 'Values': paper_steadiness.tolist()},\n",
    "            {'Quantity': 'Paper Score', 'Identifiers': papers.tolist(), 'Values': paper_score.tolist()},\n",
    "            {'Quantity': 'Reader Steadiness', 'Identifiers': readers.tolist(), 'Values': reader_steadiness.tolist()},\n",
    "            {'Quantity': 'Reader Score', 'Identifiers': readers.tolist(), 'Values': reader_score.tolist()},\n",
    "            {'Quantity': 'Author Steadiness', 'Identifiers': authors.tolist(), 'Values': author_steadiness.tolist()},\n",
    "            {'Quantity': 'Author Score', 'Identifiers': authors.tolist(), 'Values': author_score.tolist()},\n",
    "        ]\n",
    "        \n",
    "        result_quantities_filename = \"{}quantities.json\".format(result_folder_path, current_day)\n",
    "        \n",
    "        if verbose:\n",
    "            print(\"------------------------------\")\n",
    "            print(\"PRINTING QUANTITIES TO .JSON FILE AT PATH {}\".format(result_quantities_filename))\n",
    "        \n",
    "        with open(result_quantities_filename, 'w') as result_quantities_file:  \n",
    "            json.dump(dictionary, result_quantities_file)\n",
    "        result_quantities_file.close()\n",
    "            \n",
    "        # Rating and goodness matrix output handling\n",
    "        \n",
    "        rating_matrix = np.zeros((readers_number, papers_number))\n",
    "        goodness_matrix = np.zeros((readers_number, papers_number))\n",
    "                \n",
    "        for rating_index in range(csv_offset, csv_offset + current_index):\n",
    "                    \n",
    "            current_entry = linecache.getline(ratings_filename, rating_index).split(\",\")\n",
    "                                \n",
    "            # Example: <1,1,2,0.8,0>\n",
    "            # At Timestamp 1 Reader 1 gave to Paper 2 a Rating of 0.8\n",
    "            current_timestamp = int(current_entry[0])\n",
    "            current_reader = int(current_entry[1])\n",
    "            current_paper = int(current_entry[2])\n",
    "            current_rating = float(current_entry[3])\n",
    "                \n",
    "            rating_matrix[current_reader][current_paper] = current_rating\n",
    "            goodness_matrix[current_reader][current_paper] = rating_goodness[current_timestamp]\n",
    "        \n",
    "        result_ratings_filename = \"{}ratings.csv\".format(result_folder_path, current_day)\n",
    "        result_goodness_filename = \"{}goodness.csv\".format(result_folder_path, current_day)\n",
    "        \n",
    "        if verbose:\n",
    "            print(\"PRINTING RATING MATRIX TO .CSV FILE AT PATH {}\".format(result_ratings_filename))\n",
    "                \n",
    "        paper_ratings_dataframe = pd.read_csv(ratings_filename)\n",
    "        ratings_matrix = paper_ratings_dataframe.pivot_table(index=\"Reader\", columns=\"Paper\", values=\"Score\")\n",
    "        ratings_matrix.fillna(0, inplace=True)\n",
    "        ratings_matrix.to_csv(result_ratings_filename, sep=\",\", header=False, index=False)\n",
    "        \n",
    "        with open(result_ratings_filename, mode='w', newline='') as result_ratings_file:\n",
    "            ratings_writer = csv.writer(result_ratings_file, delimiter=',', quotechar='\"', quoting=csv.QUOTE_MINIMAL)\n",
    "            for rating_entry in rating_matrix:\n",
    "                ratings_writer.writerow(rating_entry)\n",
    "        result_ratings_file.close()\n",
    "            \n",
    "        if verbose:\n",
    "            print(\"PRINTING RATING GOODNESS MATRIX TO .CSV FILE AT PATH {}\".format(result_goodness_filename))\n",
    "        \n",
    "        with open(result_goodness_filename, mode='w', newline='') as result_goodness_file:\n",
    "            goodness_writer = csv.writer(result_goodness_file, delimiter=',', quotechar='\"', quoting=csv.QUOTE_MINIMAL)\n",
    "            for goodness_entry in goodness_matrix:\n",
    "                goodness_writer.writerow(goodness_entry)\n",
    "        result_goodness_file.close()\n",
    "        \n",
    "        # Info output handling\n",
    "        \n",
    "        result_elapsed_time = time.time() - start_time \n",
    "        \n",
    "        dictionary = [{'Time': result_elapsed_time}]\n",
    "        \n",
    "        result_info_filename = \"{}info.json\".format(result_folder_path, current_day)\n",
    "        \n",
    "        if verbose:\n",
    "            print(\"PRINTING INFO TO .JSON FILE AT PATH {}\".format(result_info_filename))\n",
    "            print(\"------------------------------\")\n",
    "            \n",
    "        with open(result_info_filename, 'w') as result_info_file:  \n",
    "            json.dump(dictionary, result_info_file)\n",
    "        result_info_file.close()\n",
    "        \n",
    "        if result_compression:\n",
    "            print(\"--------------------------------------\")\n",
    "            print(\"---------- COMPRESSING RESULTS ----------\")\n",
    "            archive_filename = \"{}{}.zip\".format(result_folder_path, archive_name)\n",
    "            archive_file = zipfile.ZipFile(archive_filename, 'w')\n",
    "            for folder, subfolders, files in os.walk(result_folder_path):\n",
    "                for file in files:\n",
    "                    if file.endswith('.csv') or file.endswith('.json'):\n",
    "                        archive_file.write(os.path.join(folder, file), os.path.relpath(os.path.join(folder,file), result_folder_path), compress_type = zipfile.ZIP_DEFLATED)\n",
    "                        thread = threading.Thread(\n",
    "                            target=os.remove,\n",
    "                            args=[os.path.relpath(os.path.join(folder,file))]\n",
    "                        )\n",
    "                        thread.daemon = True\n",
    "                        thread.start()\n",
    "            archive_file.close()           \n",
    "            print(\"RESULT COMPRESSED INTO A .ZIP ARCHIVE AT PATH {}\".format(archive_filename))\n",
    "            print(\"--------------------------------------\")\n",
    "            \n",
    "        file_paths = [result_ratings_filename, result_goodness_filename, result_quantities_filename, result_info_filename]\n",
    "        \n",
    "        return result_elapsed_time, file_paths\n",
    "    \n",
    "    # Function to clean unwanted results\n",
    "    \n",
    "    def clean_results(results_to_clean):\n",
    "        print(\"--------------------------------------\")\n",
    "        print(\"---------- CLEANING RESULTS ----------\")\n",
    "        for file_path in results_to_clean:\n",
    "            if os.path.isfile(file_path):\n",
    "                print(\"Deleting file at path: \", file_path)\n",
    "                thread = threading.Thread(\n",
    "                    target=os.remove,\n",
    "                    args=[file_path],\n",
    "                )\n",
    "                thread.daemon = True\n",
    "                thread.start()\n",
    "        print(\"--------------------------------------\")\n",
    "    \n",
    "    # There are many \"print\" that you can uncomment if you have to do some debugging\n",
    "    # print(\"##########\")\n",
    "        \n",
    "    start_time = time.time()\n",
    "    \n",
    "    for index in range(csv_offset, (ratings_number + csv_offset)):\n",
    "        \n",
    "        if days_serialization:\n",
    "            if index % (ratings_number_per_day * computed_days) == 0:\n",
    "                current_day = computed_days\n",
    "                written = False\n",
    "                cleaned = False\n",
    "                if days_serialization_cleaning and computed_days % days_cleaning_threshold == 0 and not cleaned:\n",
    "                     clean_results(result_file_paths)\n",
    "                     result_file_paths = []\n",
    "                     cleaned = True\n",
    "                if computed_days % days_serialization_threshold == 0 and not written:\n",
    "                    print(\"---------- DAY {}/{} ----------\".format(current_day, days_number))\n",
    "                    elapsed_time, paths = serialize_result(index, verbose=False, parameters=parameters)\n",
    "                    result_file_paths = result_file_paths + paths\n",
    "                    written = True\n",
    "                computed_days += 1\n",
    "                \n",
    "        percentage = 100*index/ratings_number\n",
    "        if percentage % 5 == 0:\n",
    "            print(\"{}/{} ({}/100%)\".format(int(index), ratings_number, int(percentage)))\n",
    "                    \n",
    "        entry = linecache.getline(ratings_filename, index).split(\",\")\n",
    "                        \n",
    "        # Example: <1,1,2,0.8,0>\n",
    "        # At Timestamp 1 Reader 1 gave to Paper 2 a Rating of 0.8\n",
    "        timestamp = int(entry[0])\n",
    "        reader = int(entry[1])\n",
    "        paper = int(entry[2])\n",
    "        rating = float(entry[3])\n",
    "        authors_of_paper = get_author(paper)\n",
    "        \n",
    "        # print(\"---------- CURRENT ENTRY ----------\")\n",
    "        # print(f\"TIMESTAMP {timestamp} - READER {reader} - PAPER {paper} - SCORE {rating}\")\n",
    "    \n",
    "        # COMPUTATION START: PAPER AND READER SCORE\n",
    "    \n",
    "        # Saving values at time t(i)\n",
    "    \n",
    "        old_paper_steadiness = paper_steadiness[paper]\n",
    "        old_paper_score = paper_score[paper]\n",
    "        old_reader_steadiness = reader_steadiness[reader]\n",
    "        old_rating_goodness = rating_goodness[timestamp]\n",
    "        old_reader_score = reader_score[reader]\n",
    "        \n",
    "        # print(\"---------- PRINTING VALUES AT TIME T(I) ----------\")\n",
    "        # print(\"PAPER STEADINESS T(I) \", old_paper_steadiness)\n",
    "        # print(\"PAPER SCORE T(I) \", old_paper_score)\n",
    "        # print(\"READER STEADINESS T(I) \", old_paper_score)\n",
    "        # print(\"RATING GOODNESS T(I) \", rating_goodness[timestamp])\n",
    "        # print(\"READER SCORE T(I) \", old_reader_score)\n",
    "    \n",
    "        # Updating values at time t(i+1)\n",
    "    \n",
    "        paper_steadiness[paper] = old_paper_steadiness + old_reader_score\n",
    "        paper_score[paper] = ((old_paper_steadiness * old_paper_score) + (old_reader_score * rating)) / paper_steadiness[paper]\n",
    "        rating_goodness[timestamp] = (1 - (m.sqrt(abs(rating - paper_score[paper]))))\n",
    "        reader_steadiness[reader] = (old_reader_steadiness + paper_steadiness[paper])\n",
    "        reader_score[reader] = (((old_reader_steadiness * old_reader_score) + (paper_steadiness[paper] * rating_goodness[timestamp])) / reader_steadiness[reader])\n",
    "    \n",
    "        # print(\"---------- PRINTING VALUES AT TIME T(I+1) ----------\")\n",
    "        # print(\"PAPER STEADINESS T(I+1) \", paper_steadiness[paper])\n",
    "        # print(\"PAPER SCORE T(I+1) \", paper_score[paper])\n",
    "        # print(\"READER STEADINESS T(I+1) \", reader_steadiness[reader])\n",
    "        # print(\"RATING GOODNESS T(I+1) \", rating_goodness[timestamp])\n",
    "        # print(\"READER SCORE T(I+1) \", reader_score[reader])\n",
    "    \n",
    "        # COMPUTATION START: AUTHOR SCORE\n",
    "    \n",
    "        for author in authors_of_paper :\n",
    "            # Saving values at time t(i)\n",
    "    \n",
    "            old_author_steadiness = author_steadiness[author]\n",
    "            old_author_score = author_score[author]\n",
    "    \n",
    "            # Updating values at time t(i+1)7\n",
    "    \n",
    "            author_steadiness[author] = old_author_steadiness + old_reader_score\n",
    "            author_score[author] = ((old_author_steadiness * old_author_score) + (old_reader_score * rating)) / author_steadiness[author]\n",
    "    \n",
    "        # COMPUTATION START: PROPAGATING CHANGES TO PREVIOUS READERS\n",
    "            \n",
    "        previous_ratings = []        \n",
    "        with open(ratings_filename) as rating_file:\n",
    "            raw_previous_ratings = deque([next(rating_file) for x in range(csv_offset, (index + csv_offset))])\n",
    "            raw_previous_ratings.popleft()\n",
    "        rating_file.close()\n",
    "        for raw_previous_rating in raw_previous_ratings:\n",
    "            previous_rating = raw_previous_rating.split(\",\")[:-1]\n",
    "            previous_ratings.append(previous_rating)\n",
    "        previous_ratings = np.array(previous_ratings, dtype=float)\n",
    "        previous_ratings = previous_ratings[\n",
    "             (previous_ratings[:,1]!=float(reader)) &\n",
    "             (previous_ratings[:,2]==float(paper))\n",
    "        ]            \n",
    "                       \n",
    "        # print(\" ----- PREVIOUS PAPER RATINGS -----\")\n",
    "    \n",
    "        for previous_index, previous_entry in enumerate(previous_ratings):\n",
    "            \n",
    "            # Example: <1,1,2,0.8,0>\n",
    "            # At Timestamp 1 Reader 1 gave to Paper 2 a Rating of 0.8 written by Author 0\n",
    "            previous_timestamp = int(previous_entry[0])\n",
    "            previous_reader = int(previous_entry[1])\n",
    "            previous_paper = int(previous_entry[2])\n",
    "            previous_rating = previous_entry[3]\n",
    "    \n",
    "            # print(f\"PREVIOUS TIMESTAMP {previous_timestamp} - PREVIOUS READER {previous_reader} - PREVIOUS PAPER {previous_paper} - PREVIOUS RATING {previous_rating}\")\n",
    "    \n",
    "            # Saving previous values at time t(i)\n",
    "    \n",
    "            old_previous_reader_steadiness = reader_steadiness[previous_reader]\n",
    "            old_previous_reader_score = reader_score[previous_reader]\n",
    "            old_previous_rating = previous_rating\n",
    "            old_previous_rating_goodness = rating_goodness[previous_timestamp]\n",
    "    \n",
    "            # Updating previous values at time t(i+1)\n",
    "    \n",
    "            rating_goodness[previous_timestamp] = 1 - (m.sqrt(abs(old_previous_rating - paper_score[paper])))\n",
    "            reader_steadiness[previous_reader] = (old_previous_reader_steadiness + old_reader_score)\n",
    "            reader_score[previous_reader] = (\n",
    "                                                (old_previous_reader_steadiness * old_previous_reader_score) -\n",
    "                                                (old_paper_steadiness * old_previous_rating_goodness) +\n",
    "                                                (paper_steadiness[paper] * rating_goodness[previous_timestamp])\n",
    "                                            ) / reader_steadiness[previous_reader]\n",
    "               \n",
    "        # print(\" ----- PREVIOUS PAPER RATINGS END -----\")\n",
    "            \n",
    "        # print(\"---------- PRINTING FINAL VALUES AT TIME T(I+1) ----------\")\n",
    "        # print(\"PAPER STEADINESS: \", paper_steadiness)\n",
    "        # print(\"PAPER SCORE: \", paper_score)\n",
    "        # print(\"READER STEADINESS: \", reader_steadiness)\n",
    "        # print(\"READER SCORE: \", reader_score)\n",
    "        # print(\"##########\")\n",
    "    \n",
    "    elapsed_time, result_file_paths = serialize_result(ratings_number, verbose=True, parameters=parameters)\n",
    "    print(\"ELAPSED TIME: \", elapsed_time)\n",
    "    \n",
    "    # ----- ALGORITHM ENDS HERE ----- #\n",
    "    \n",
    "    # Summary\n",
    "    \n",
    "    #print(\"PAPER STEADINESS:  \", paper_steadiness)\n",
    "    #print(\"PAPER SCORE:       \", paper_score)\n",
    "    #print(\"READER STEADINESS: \", reader_steadiness)\n",
    "    #print(\"READER SCORE:      \", reader_score)\n",
    "    #print(\"AUTHOR STEADINESS: \", author_steadiness)\n",
    "    #print(\"AUTHOR SCORE:      \", author_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "outputs": [
    {
     "name": "stdout",
     "text": [
      "---------------------------------\n----------- SHUFFLE 0 -----------\n"
     ],
     "output_type": "stream"
    },
    {
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-15-d6854092aaca>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     66\u001b[0m     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"----------- SHUFFLE {} -----------\"\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mindex_shuffle\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     67\u001b[0m     \u001b[0mseed_shuffle_1_special\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcurrent_shuffle\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mindex_shuffle\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 68\u001b[1;33m     \u001b[0mreadersourcing\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mseed_shuffle_1_special\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     69\u001b[0m \u001b[1;31m#except ValueError as error:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     70\u001b[0m \u001b[1;31m#    print(repr(error))\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-14-ffc30a351aa0>\u001b[0m in \u001b[0;36mreadersourcing\u001b[1;34m(parameters)\u001b[0m\n\u001b[0;32m     56\u001b[0m     \u001b[0mauthors_filename\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m\"{}authors.csv\"\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdataset_folder_path\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     57\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 58\u001b[1;33m     \u001b[0minfo\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minfo_filename\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     59\u001b[0m     \u001b[0mpaper_authors\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mauthors_filename\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     60\u001b[0m     \u001b[0mpaper_authors\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpaper_authors\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Ambienti\\Anaconda3\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36mparser_f\u001b[1;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, dialect, error_bad_lines, warn_bad_lines, delim_whitespace, low_memory, memory_map, float_precision)\u001b[0m\n\u001b[0;32m    683\u001b[0m         )\n\u001b[0;32m    684\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 685\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    686\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    687\u001b[0m     \u001b[0mparser_f\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__name__\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Ambienti\\Anaconda3\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36m_read\u001b[1;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[0;32m    455\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    456\u001b[0m     \u001b[1;31m# Create the parser.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 457\u001b[1;33m     \u001b[0mparser\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mTextFileReader\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfp_or_buf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    458\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    459\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mchunksize\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0miterator\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Ambienti\\Anaconda3\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[0;32m    893\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"has_index_names\"\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mkwds\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"has_index_names\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    894\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 895\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_make_engine\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    896\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    897\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Ambienti\\Anaconda3\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36m_make_engine\u001b[1;34m(self, engine)\u001b[0m\n\u001b[0;32m   1133\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_make_engine\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mengine\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"c\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1134\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mengine\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m\"c\"\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1135\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_engine\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mCParserWrapper\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1136\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1137\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mengine\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m\"python\"\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Ambienti\\Anaconda3\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, src, **kwds)\u001b[0m\n\u001b[0;32m   1904\u001b[0m         \u001b[0mkwds\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"usecols\"\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0musecols\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1905\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1906\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_reader\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mparsers\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTextReader\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1907\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0munnamed_cols\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_reader\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0munnamed_cols\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1908\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader.__cinit__\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader._setup_parser_source\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] File b'../data/seed_shuffle_1_special/info.csv' does not exist: b'../data/seed_shuffle_1_special/info.csv'"
     ],
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] File b'../data/seed_shuffle_1_special/info.csv' does not exist: b'../data/seed_shuffle_1_special/info.csv'",
     "output_type": "error"
    }
   ],
   "source": [
    "# Samples\n",
    "\n",
    "# ------------------------------\n",
    "# ---------- SAMPLE 1 ----------\n",
    "# ------------------------------\n",
    "\n",
    "# ground_truth_2 = ReadersourcingParameters(\n",
    "#     dataset_name=\"ground_truth_2\", \n",
    "#     dataset_folder_path=\"../data/{}/\"\n",
    "# )\n",
    "# try:\n",
    "#     readersourcing(ground_truth_2)\n",
    "# except ValueError as error:\n",
    "#      print(repr(error))\n",
    "\n",
    "# ------------------------------\n",
    "# ---------- SAMPLE 2 ----------\n",
    "# ------------------------------\n",
    "\n",
    "# seed_p_1_beta = ReadersourcingParameters(\n",
    "#     dataset_name=\"seed_1/p_1_beta\", \n",
    "#     dataset_folder_path=\"../data/{}/\", \n",
    "#     days_serialization=True,\n",
    "#     days_number=30,\n",
    "#     days_serialization_threshold=5,\n",
    "#  )\n",
    "# \n",
    "# readersourcing(seed_p_1_beta)\n",
    " \n",
    "# ------------------------------\n",
    "# ---------- SAMPLE 3 ----------\n",
    "# ------------------------------\n",
    "\n",
    "# seed_shuffle_1 = ReadersourcingParameters(\n",
    "#      dataset_name=\"seed_shuffle_1\", \n",
    "#      dataset_folder_path=\"../data/{}/\", \n",
    "#      data_shuffled=True, \n",
    "#      current_shuffle = 0,\n",
    "#      shuffle_amount=100\n",
    "#  )\n",
    "#  \n",
    "# try:\n",
    "#     for index_shuffle in range(seed_shuffle_1.shuffle_amount):\n",
    "#         print(\"---------------------------------\")\n",
    "#         print(\"----------- SHUFFLE {} -----------\".format(index_shuffle))\n",
    "#         seed_shuffle_1.current_shuffle = index_shuffle\n",
    "#         readersourcing(seed_shuffle_1)\n",
    "# except ValueError as error:\n",
    "#     print(repr(error))\n",
    "\n",
    "# ------------------------------\n",
    "# ---------- SAMPLE 4 ----------\n",
    "# ------------------------------\n",
    "\n",
    "seed_shuffle_1_special = ReadersourcingParameters(\n",
    "     dataset_name=\"seed_shuffle_1_special\", \n",
    "     dataset_folder_path=\"../data/{}/\", \n",
    "     data_shuffled=True, \n",
    "     current_shuffle = 0,\n",
    "     shuffle_amount=100\n",
    " )\n",
    " \n",
    "try:\n",
    "    for index_shuffle in range(seed_shuffle_1_special.shuffle_amount):\n",
    "        print(\"---------------------------------\")\n",
    "        print(\"----------- SHUFFLE {} -----------\".format(index_shuffle))\n",
    "        seed_shuffle_1_special.current_shuffle = index_shuffle\n",
    "        readersourcing(seed_shuffle_1_special)\n",
    "except ValueError as error:\n",
    "    print(repr(error))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "python3",
   "language": "python",
   "display_name": "Python 3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  },
  "pycharm": {
   "stem_cell": {
    "cell_type": "raw",
    "source": [],
    "metadata": {
     "collapsed": false
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}