{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true,
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import math as m\n",
    "import linecache\n",
    "from collections import deque\n",
    "import csv\n",
    "import zipfile\n",
    "import threading\n",
    "import numpy as np\n",
    "import os\n",
    "import json\n",
    "import time\n",
    "\n",
    "# Parameter setting\n",
    "\n",
    "dataset_name = \"sample\"\n",
    "days_serialization = True\n",
    "days_serialization_threshold = 2\n",
    "days_number = 10\n",
    "# days_cleaning_threshold = 4\n",
    "# result_compression = True\n",
    "# archive_name = \"result\"\n",
    "\n",
    "# Reader score must be set to a very small value otherwise there will be a division by 0\n",
    "\n",
    "epsilon = 0.000001\n",
    "\n",
    "# CSV file parsing\n",
    "\n",
    "dataset_folder_path = \"../data/{}/\".format(dataset_name)\n",
    "info_filename = \"{}info.csv\".format(dataset_folder_path)\n",
    "ratings_filename = \"{}ratings.csv\".format(dataset_folder_path)\n",
    "authors_filename = \"{}authors.csv\".format(dataset_folder_path)\n",
    "\n",
    "info = pd.read_csv(info_filename)\n",
    "paper_authors = pd.read_csv(authors_filename)\n",
    "paper_authors = paper_authors.values\n",
    "paper_ratings = pd.read_csv(ratings_filename)\n",
    "paper_ratings = paper_ratings.values\n",
    "\n",
    "csv_offset = 2\n",
    "\n",
    "# Initial Readersourcing setup\n",
    "\n",
    "dataset_name = info[\"Dataset\"][0]\n",
    "papers_number = info[\"Paper\"][0]\n",
    "readers_number = info[\"Reader\"][0]\n",
    "ratings_number = info[\"Rating\"][0]\n",
    "ratings_number_per_day = m.floor(int(ratings_number / days_number))\n",
    "authors_number = info[\"Author\"][0]\n",
    "papers = np.arange(papers_number)\n",
    "readers = np.arange(readers_number)\n",
    "ratings = np.arange(ratings_number)\n",
    "authors = np.arange(authors_number)\n",
    "paper_steadiness = np.zeros(papers_number)\n",
    "paper_score = np.zeros(papers_number)\n",
    "rating_goodness = np.zeros(ratings_number)\n",
    "reader_steadiness = np.zeros(readers_number)\n",
    "reader_score = np.zeros(readers_number)\n",
    "reader_score.fill(epsilon)\n",
    "author_steadiness = np.zeros(authors_number)\n",
    "author_score = np.zeros(authors_number)\n",
    "\n",
    "# Day serialization handling\n",
    "\n",
    "computed_days = 1\n",
    "written = False\n",
    "# cleaned = False\n",
    "\n",
    "# Output handling\n",
    "\n",
    "result_file_paths = []\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [
    {
     "name": "stdout",
     "text": [
      "------------------------------\n---------- DAY 0/10 ----------\n0/0 (0/100%)\n",
      "402/4020 (10/100%)\n---------- DAY 2/10 ----------\n",
      "804/4020 (20/100%)\n",
      "1206/4020 (30/100%)\n---------- DAY 4/10 ----------\n",
      "1608/4020 (40/100%)\n",
      "2010/4020 (50/100%)\n---------- DAY 6/10 ----------\n",
      "2412/4020 (60/100%)\n",
      "2814/4020 (70/100%)\n---------- DAY 8/10 ----------\n",
      "3216/4020 (80/100%)\n",
      "3618/4020 (90/100%)\n---------- DAY 10/10 ----------\n",
      "4020/4020 (100/100%)\n------------------------------\nPRINTING QUANTITIES TO .JSON FILE AT PATH ../models/sample/readersourcing/day_9/quantities.json\nPRINTING RATING MATRIX TO .CSV FILE AT PATH ../models/sample/readersourcing/day_9/ratings.csv\nPRINTING RATING GOODNESS MATRIX TO .CSV FILE AT PATH ../models/sample/readersourcing/day_9/goodness.csv\nPRINTING INFO TO .JSON FILE AT PATH ../models/sample/readersourcing/day_9/info.json\nELAPSED TIME:  (24.582000017166138, ['../models/sample/readersourcing/day_9/ratings.csv', '../models/sample/readersourcing/day_9/goodness.csv', '../models/sample/readersourcing/day_9/quantities.json', '../models/sample/readersourcing/day_9/info.json'])\n"
     ],
     "output_type": "stream"
    }
   ],
   "source": [
    "\n",
    "# ----- ALGORITHM STARTS HERE ----- #\n",
    "\n",
    "start_time = time.time()\n",
    "\n",
    "def get_author(current_paper) :\n",
    "    \n",
    "    found_authors = []\n",
    "    \n",
    "    for author_index, author_entry in enumerate(paper_authors) :\n",
    "        current_author = int(author_entry[0])\n",
    "        written_papers = author_entry[1].split(\";\")\n",
    "        written_papers = [int(x) for x in written_papers]\n",
    "        if current_paper in written_papers :\n",
    "            found_authors.append(current_author)\n",
    "            \n",
    "    return np.asarray(found_authors)\n",
    "\n",
    "# Function to output result to file\n",
    "\n",
    "def serialize_result(day, current_index, verbose):\n",
    "    \n",
    "    base_path = \"../models/{}/readersourcing/\".format(dataset_name)\n",
    "    \n",
    "    if days_serialization:\n",
    "        result_folder_path = \"{}day_{}/\".format(base_path, day)\n",
    "    else:\n",
    "        result_folder_path = base_path\n",
    "    \n",
    "    os.makedirs(result_folder_path, exist_ok=True)\n",
    "\n",
    "    # Quantities output handling\n",
    "\n",
    "    dictionary = [\n",
    "        {'Quantity': 'Paper Steadiness', 'Identifiers': papers.tolist(), 'Values': paper_steadiness.tolist()},\n",
    "        {'Quantity': 'Paper Score', 'Identifiers': papers.tolist(), 'Values': paper_score.tolist()},\n",
    "        {'Quantity': 'Reader Steadiness', 'Identifiers': readers.tolist(), 'Values': reader_steadiness.tolist()},\n",
    "        {'Quantity': 'Reader Score', 'Identifiers': readers.tolist(), 'Values': reader_score.tolist()},\n",
    "        {'Quantity': 'Author Steadiness', 'Identifiers': authors.tolist(), 'Values': author_steadiness.tolist()},\n",
    "        {'Quantity': 'Author Score', 'Identifiers': authors.tolist(), 'Values': author_score.tolist()},\n",
    "    ]\n",
    "    \n",
    "    result_quantities_filename = \"{}quantities.json\".format(result_folder_path, day)\n",
    "    \n",
    "    if verbose:\n",
    "        print(\"PRINTING QUANTITIES TO .JSON FILE AT PATH {}\".format(result_quantities_filename))\n",
    "    \n",
    "    with open(result_quantities_filename, 'w') as result_quantities_file:  \n",
    "        json.dump(dictionary, result_quantities_file)\n",
    "    result_quantities_file.close()\n",
    "        \n",
    "    # Rating and goodness matrix output handling\n",
    "    \n",
    "    rating_matrix = np.zeros((readers_number, papers_number))\n",
    "    goodness_matrix = np.zeros((readers_number, papers_number))\n",
    "    \n",
    "    for rating_index in range(csv_offset, current_index):\n",
    "                \n",
    "        current_entry = linecache.getline(ratings_filename, rating_index).split(\",\")\n",
    "                \n",
    "        # Example: <1,1,2,0.8,0>\n",
    "        # At Timestamp 1 Reader 1 gave to Paper 2 a Rating of 0.8\n",
    "        current_timestamp = int(current_entry[0])\n",
    "        current_reader = int(current_entry[1])\n",
    "        current_paper = int(current_entry[2])\n",
    "        current_rating = float(current_entry[3])\n",
    "            \n",
    "        rating_matrix[current_reader][current_paper] = current_rating\n",
    "        goodness_matrix[current_reader][current_paper] = rating_goodness[current_timestamp]\n",
    "    \n",
    "    result_ratings_filename = \"{}ratings.csv\".format(result_folder_path, day)\n",
    "    result_goodness_filename = \"{}goodness.csv\".format(result_folder_path, day)\n",
    "    \n",
    "    if verbose:\n",
    "        print(\"PRINTING RATING MATRIX TO .CSV FILE AT PATH {}\".format(result_ratings_filename))\n",
    "            \n",
    "    paper_ratings_dataframe = pd.read_csv(ratings_filename)\n",
    "    ratings_matrix = paper_ratings_dataframe.pivot_table(index=\"Reader\", columns=\"Paper\", values=\"Score\")\n",
    "    ratings_matrix.fillna(0, inplace=True)\n",
    "    ratings_matrix.to_csv(result_ratings_filename, sep=\",\", header=False, index=False)\n",
    "        \n",
    "    if verbose:\n",
    "        print(\"PRINTING RATING GOODNESS MATRIX TO .CSV FILE AT PATH {}\".format(result_goodness_filename))\n",
    "    \n",
    "    with open(result_goodness_filename, mode='w', newline='') as result_goodness_file:\n",
    "        goodness_writer = csv.writer(result_goodness_file, delimiter=',', quotechar='\"', quoting=csv.QUOTE_MINIMAL)\n",
    "        for goodness_entry in goodness_matrix:\n",
    "            goodness_writer.writerow(goodness_entry)\n",
    "    result_goodness_file.close()\n",
    "    \n",
    "    # Info output handling\n",
    "    \n",
    "    result_elapsed_time = time.time() - start_time \n",
    "    \n",
    "    dictionary = [{'Time': result_elapsed_time}]\n",
    "    \n",
    "    result_info_filename = \"{}info.json\".format(result_folder_path, day)\n",
    "    \n",
    "    if verbose:\n",
    "        print(\"PRINTING INFO TO .JSON FILE AT PATH {}\".format(result_info_filename))\n",
    "        \n",
    "    with open(result_info_filename, 'w') as result_info_file:  \n",
    "        json.dump(dictionary, result_info_file)\n",
    "    result_info_file.close()\n",
    "    \n",
    "    #if result_compression:\n",
    "    #    archive_filename = \"{}{}.zip\".format(result_folder_path, archive_name)\n",
    "    #    archive_file = zipfile.ZipFile(archive_filename, 'w')\n",
    "    #    for folder, subfolders, files in os.walk(result_folder_path):\n",
    "    #        for file in files:\n",
    "    #            if file.endswith('.csv') or file.endswith('.json'):\n",
    "    #                archive_file.write(os.path.join(folder, file), os.path.relpath(os.path.join(folder,file), result_folder_path), compress_type = zipfile.ZIP_DEFLATED)\n",
    "    #    archive_file.close()           \n",
    "    #    print(\"RESULT COMPRESSED INTO A .ZIP ARCHIVE AT PATH {}\".format(archive_filename))\n",
    "                \n",
    "    file_paths = [result_ratings_filename, result_goodness_filename, result_quantities_filename, result_info_filename]\n",
    "    \n",
    "    return result_elapsed_time, file_paths\n",
    "\n",
    "def clean_results(results_to_clean):\n",
    "    print(\"*********************************\")\n",
    "    print(\"********** CLEANING RESULTS **********\")\n",
    "    for file_path in results_to_clean:\n",
    "        if os.path.isfile(file_path):\n",
    "            print(\"Deleting file at path: \", file_path)\n",
    "            thread = threading.Thread(\n",
    "                target=os.remove,\n",
    "                args=[file_path],\n",
    "            )\n",
    "            thread.daemon = True\n",
    "            thread.start()\n",
    "    print(\"*********************************\")\n",
    "\n",
    "# There are many \"print\" that you can uncomment if you have to do some debugging\n",
    "# print(\"##########\")\n",
    "\n",
    "print(\"------------------------------\")\n",
    "if days_serialization:\n",
    "    print(\"---------- DAY 0/{} ----------\".format(days_number))\n",
    "print(\"0/0 (0/100%)\")\n",
    "\n",
    "for index in range(csv_offset, (ratings_number + csv_offset)):\n",
    "    \n",
    "    percentage = 100*index/ratings_number\n",
    "    if percentage % 2 == 0:\n",
    "        print(\"{}/{} ({}/100%)\".format(int(index), ratings_number, int(percentage)))\n",
    "    \n",
    "    if days_serialization:\n",
    "        if index % (ratings_number_per_day * computed_days) == 0:\n",
    "            computed_days += 1\n",
    "            written = False\n",
    "            #cleaned = False\n",
    "            # if computed_days % days_cleaning_threshold == 0 and not cleaned:\n",
    "            #     clean_results(result_file_paths)\n",
    "            #     result_file_paths = []\n",
    "            #     cleaned = True\n",
    "            if computed_days % days_serialization_threshold == 0 and not written:\n",
    "                print(\"---------- DAY {}/{} ----------\".format(computed_days, days_number))\n",
    "                elapsed_time, paths = serialize_result(computed_days, index, verbose=False)\n",
    "                result_file_paths = result_file_paths + paths\n",
    "                written = True\n",
    "\n",
    "    entry = linecache.getline(ratings_filename, index).split(\",\")\n",
    "                                                                     \n",
    "    # Example: <1,1,2,0.8,0>\n",
    "    # At Timestamp 1 Reader 1 gave to Paper 2 a Rating of 0.8\n",
    "    timestamp = int(entry[0])\n",
    "    reader = int(entry[1])\n",
    "    paper = int(entry[2])\n",
    "    rating = float(entry[3])\n",
    "    authors_of_paper = get_author(paper)\n",
    "    \n",
    "    # print(\"---------- CURRENT ENTRY ----------\")\n",
    "    # print(f\"TIMESTAMP {timestamp} - READER {reader} - PAPER {paper} - SCORE {rating}\")\n",
    "\n",
    "    # COMPUTATION START: PAPER AND READER SCORE\n",
    "\n",
    "    # Saving values at time t(i)\n",
    "\n",
    "    old_paper_steadiness = paper_steadiness[paper]\n",
    "    old_paper_score = paper_score[paper]\n",
    "    old_reader_steadiness = reader_steadiness[reader]\n",
    "    old_rating_goodness = rating_goodness[timestamp]\n",
    "    old_reader_score = reader_score[reader]\n",
    "    \n",
    "    # print(\"---------- PRINTING VALUES AT TIME T(I) ----------\")\n",
    "    # print(\"PAPER STEADINESS T(I) \", old_paper_steadiness)\n",
    "    # print(\"PAPER SCORE T(I) \", old_paper_score)\n",
    "    # print(\"READER STEADINESS T(I) \", old_paper_score)\n",
    "    # print(\"RATING GOODNESS T(I) \", rating_goodness[timestamp])\n",
    "    # print(\"READER SCORE T(I) \", old_reader_score)\n",
    "\n",
    "    # Updating values at time t(i+1)\n",
    "\n",
    "    paper_steadiness[paper] = old_paper_steadiness + old_reader_score\n",
    "    paper_score[paper] = ((old_paper_steadiness * old_paper_score) + (old_reader_score * rating)) / paper_steadiness[paper]\n",
    "    rating_goodness[timestamp] = (1 - (m.sqrt(abs(rating - paper_score[paper]))))\n",
    "    reader_steadiness[reader] = (old_reader_steadiness + paper_steadiness[paper])\n",
    "    reader_score[reader] = (((old_reader_steadiness * old_reader_score) + (paper_steadiness[paper] * rating_goodness[timestamp])) / reader_steadiness[reader])\n",
    "\n",
    "    # print(\"---------- PRINTING VALUES AT TIME T(I+1) ----------\")\n",
    "    # print(\"PAPER STEADINESS T(I+1) \", paper_steadiness[paper])\n",
    "    # print(\"PAPER SCORE T(I+1) \", paper_score[paper])\n",
    "    # print(\"READER STEADINESS T(I+1) \", reader_steadiness[reader])\n",
    "    # print(\"RATING GOODNESS T(I+1) \", rating_goodness[timestamp])\n",
    "    # print(\"READER SCORE T(I+1) \", reader_score[reader])\n",
    "\n",
    "    # COMPUTATION START: AUTHOR SCORE\n",
    "\n",
    "    for author in authors_of_paper :\n",
    "        # Saving values at time t(i)\n",
    "\n",
    "        old_author_steadiness = author_steadiness[author]\n",
    "        old_author_score = author_score[author]\n",
    "\n",
    "        # Updating values at time t(i+1)7\n",
    "\n",
    "        author_steadiness[author] = old_author_steadiness + old_reader_score\n",
    "        author_score[author] = ((old_author_steadiness * old_author_score) + (old_reader_score * rating)) / author_steadiness[author]\n",
    "\n",
    "    # COMPUTATION START: PROPAGATING CHANGES TO PREVIOUS READERS\n",
    "        \n",
    "    previous_ratings = []        \n",
    "    with open(ratings_filename) as rating_file:\n",
    "        raw_previous_ratings = deque([next(rating_file) for x in range(csv_offset, (index + csv_offset))])\n",
    "        raw_previous_ratings.popleft()\n",
    "    rating_file.close()\n",
    "    for raw_previous_rating in raw_previous_ratings:\n",
    "        previous_rating = raw_previous_rating.split(\",\")\n",
    "        previous_ratings.append(previous_rating)\n",
    "    previous_ratings = np.array(previous_ratings, dtype=float)\n",
    "    previous_ratings = previous_ratings[\n",
    "         (previous_ratings[:,1]!=float(reader)) &\n",
    "         (previous_ratings[:,2]==float(paper))\n",
    "    ]            \n",
    "                   \n",
    "    # print(\" ----- PREVIOUS PAPER RATINGS -----\")\n",
    "\n",
    "    for previous_index, previous_entry in enumerate(previous_ratings):\n",
    "        \n",
    "        # Example: <1,1,2,0.8,0>\n",
    "        # At Timestamp 1 Reader 1 gave to Paper 2 a Rating of 0.8 written by Author 0\n",
    "        previous_timestamp = int(previous_entry[0])\n",
    "        previous_reader = int(previous_entry[1])\n",
    "        previous_paper = int(previous_entry[2])\n",
    "        previous_rating = previous_entry[3]\n",
    "\n",
    "        # print(f\"PREVIOUS TIMESTAMP {previous_timestamp} - PREVIOUS READER {previous_reader} - PREVIOUS PAPER {previous_paper} - PREVIOUS RATING {previous_rating}\")\n",
    "\n",
    "        # Saving previous values at time t(i)\n",
    "\n",
    "        old_previous_reader_steadiness = reader_steadiness[previous_reader]\n",
    "        old_previous_reader_score = reader_score[previous_reader]\n",
    "        old_previous_rating = previous_rating\n",
    "        old_previous_rating_goodness = rating_goodness[previous_timestamp]\n",
    "\n",
    "        # Updating previous values at time t(i+1)\n",
    "\n",
    "        rating_goodness[previous_timestamp] = 1 - (m.sqrt(abs(old_previous_rating - paper_score[paper])))\n",
    "        reader_steadiness[previous_reader] = (old_previous_reader_steadiness + old_reader_score)\n",
    "        reader_score[previous_reader] = (\n",
    "                                            (old_previous_reader_steadiness * old_previous_reader_score) -\n",
    "                                            (old_paper_steadiness * old_previous_rating_goodness) +\n",
    "                                            (paper_steadiness[paper] * rating_goodness[previous_timestamp])\n",
    "                                        ) / reader_steadiness[previous_reader]\n",
    "           \n",
    "    # print(\" ----- PREVIOUS PAPER RATINGS END -----\")\n",
    "        \n",
    "    # print(\"---------- PRINTING FINAL VALUES AT TIME T(I+1) ----------\")\n",
    "    # print(\"PAPER STEADINESS: \", paper_steadiness)\n",
    "    # print(\"PAPER SCORE: \", paper_score)\n",
    "    # print(\"READER STEADINESS: \", reader_steadiness)\n",
    "    # print(\"READER SCORE: \", reader_score)\n",
    "    # print(\"##########\")\n",
    "\n",
    "print(\"------------------------------\")\n",
    "elapsed_time = serialize_result((days_number-1), ratings_number, verbose=True)\n",
    "print(\"ELAPSED TIME: \", elapsed_time)\n",
    "\n",
    "# ----- ALGORITHM ENDS HERE ----- #\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "text": [
      "PAPER STEADINESS:   [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\nPAPER SCORE:        [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\nREADER STEADINESS:  [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n 0. 0. 0. 0. 0. 0.]\nREADER SCORE:       [1.e-06 1.e-06 1.e-06 1.e-06 1.e-06 1.e-06 1.e-06 1.e-06 1.e-06 1.e-06\n 1.e-06 1.e-06 1.e-06 1.e-06 1.e-06 1.e-06 1.e-06 1.e-06 1.e-06 1.e-06\n 1.e-06 1.e-06 1.e-06 1.e-06 1.e-06 1.e-06 1.e-06 1.e-06 1.e-06 1.e-06\n 1.e-06 1.e-06 1.e-06 1.e-06 1.e-06 1.e-06 1.e-06 1.e-06 1.e-06 1.e-06\n 1.e-06 1.e-06 1.e-06 1.e-06 1.e-06 1.e-06 1.e-06 1.e-06 1.e-06 1.e-06\n 1.e-06 1.e-06 1.e-06 1.e-06 1.e-06 1.e-06 1.e-06 1.e-06 1.e-06 1.e-06\n 1.e-06 1.e-06 1.e-06 1.e-06 1.e-06 1.e-06 1.e-06 1.e-06 1.e-06 1.e-06\n 1.e-06 1.e-06 1.e-06 1.e-06 1.e-06 1.e-06 1.e-06 1.e-06 1.e-06 1.e-06\n 1.e-06 1.e-06 1.e-06 1.e-06 1.e-06 1.e-06 1.e-06 1.e-06 1.e-06 1.e-06\n 1.e-06 1.e-06 1.e-06 1.e-06 1.e-06 1.e-06 1.e-06 1.e-06 1.e-06 1.e-06\n 1.e-06 1.e-06 1.e-06 1.e-06 1.e-06 1.e-06 1.e-06 1.e-06 1.e-06 1.e-06\n 1.e-06 1.e-06 1.e-06 1.e-06 1.e-06 1.e-06 1.e-06 1.e-06 1.e-06 1.e-06\n 1.e-06 1.e-06 1.e-06 1.e-06 1.e-06 1.e-06 1.e-06 1.e-06 1.e-06 1.e-06\n 1.e-06 1.e-06 1.e-06 1.e-06 1.e-06 1.e-06 1.e-06 1.e-06 1.e-06 1.e-06\n 1.e-06 1.e-06 1.e-06 1.e-06 1.e-06 1.e-06 1.e-06 1.e-06 1.e-06 1.e-06]\nAUTHOR STEADINESS:  [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n 0.]\nAUTHOR SCORE:       [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n 0.]\n"
     ],
     "output_type": "stream"
    }
   ],
   "source": [
    "# Summary\n",
    "\n",
    "print(\"PAPER STEADINESS:  \", paper_steadiness)\n",
    "print(\"PAPER SCORE:       \", paper_score)\n",
    "print(\"READER STEADINESS: \", reader_steadiness)\n",
    "print(\"READER SCORE:      \", reader_score)\n",
    "print(\"AUTHOR STEADINESS: \", author_steadiness)\n",
    "print(\"AUTHOR SCORE:      \", author_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "python3",
   "language": "python",
   "display_name": "Python 3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  },
  "pycharm": {
   "stem_cell": {
    "cell_type": "raw",
    "source": [],
    "metadata": {
     "collapsed": false
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}