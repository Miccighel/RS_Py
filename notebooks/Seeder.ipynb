{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 146,
   "outputs": [
    {
     "name": "stdout",
     "text": [
      "DATASET NAME:  seed_shuffle_1\nDATASET FOLDER PATH:  ../data/seed_shuffle_1/\nINFO FILE PATH:  ../data/seed_shuffle_1/info.csv\nRATINGS FILE PATH:  ../data/seed_shuffle_1/ratings.csv\nAUTHORS FILE PATH:  ../data/seed_shuffle_1/authors.csv\n"
     ],
     "output_type": "stream"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import math as m\n",
    "import os\n",
    "import collections\n",
    "import csv\n",
    "import random as rn\n",
    "from scipy.stats import beta as beta\n",
    "\n",
    "# ------------------------------\n",
    "# ----- PARAMETERS & SETUP -----\n",
    "# ------------------------------\n",
    "\n",
    "# Parameter setting\n",
    "\n",
    "dataset_name = \"seed_shuffle_1\"\n",
    "papers_number = 300\n",
    "readers_number = 1000\n",
    "authors_number = 40\n",
    "months_number = 1\n",
    "paper_frequencies = [\n",
    "    2 * months_number, \n",
    "    6 * months_number, \n",
    "    8 * months_number, \n",
    "    14 * months_number, \n",
    "    20 * months_number\n",
    "]\n",
    "shuffling = True\n",
    "shuffle_number = 100\n",
    "\n",
    "assert (papers_number > (sum(paper_frequencies)) and (papers_number % 10) == 0), \\\n",
    "    \"ERROR: papers_number must be greater than (equal to) {} and it must be a multiple of 10.\".format(sum(paper_frequencies)) \n",
    "\n",
    "# Seed folder path\n",
    "\n",
    "dataset_folder_path = \"../data/{}/\".format(dataset_name)\n",
    "dataset_shuffle_folder_path = \"../data/{}/shuffle/\".format(dataset_name)\n",
    "info_file_path = \"{}info.csv\".format(dataset_folder_path)\n",
    "ratings_file_path = \"{}ratings.csv\".format(dataset_folder_path)\n",
    "authors_file_path = \"{}authors.csv\".format(dataset_folder_path)\n",
    "stats_file_path = \"{}stats.csv\".format(dataset_folder_path)\n",
    "\n",
    "# Setting up arrays\n",
    "\n",
    "papers = np.arange(papers_number)\n",
    "readers = np.arange(readers_number)\n",
    "authors = np.arange(authors_number)\n",
    "\n",
    "os.makedirs(dataset_folder_path, exist_ok=True)\n",
    "\n",
    "print(\"DATASET NAME: \", dataset_name)\n",
    "print(\"DATASET FOLDER PATH: \", dataset_folder_path)\n",
    "print(\"INFO FILE PATH: \", info_file_path)\n",
    "print(\"RATINGS FILE PATH: \", ratings_file_path)\n",
    "print(\"AUTHORS FILE PATH: \", authors_file_path)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "outputs": [
    {
     "name": "stdout",
     "text": [
      "---------- PAPER DISTRIBUTIONS GENERATION STARTED ----------\n0/300 (0/100%)\n30/300 (10/100%)\n60/300 (20/100%)\n90/300 (30/100%)\n120/300 (40/100%)\n150/300 (50/100%)\n180/300 (60/100%)\n210/300 (70/100%)\n240/300 (80/100%)\n270/300 (90/100%)\n300/300 (100/100%)\n{'0': {'papers_ids': [261, 262, 260, 139, 231, 167, 78, 227, 143, 188, 156, 133, 241, 178, 258], 'papers_amount': 15}, '1': {'papers_ids': [33, 152, 233, 220, 96, 276, 157, 224, 162, 282, 203, 71, 144, 36, 182, 159, 150, 17, 292, 18, 158, 287, 175, 221, 124, 257, 155, 209, 264, 190, 138, 10, 129, 161, 83, 125, 277, 141, 60, 65, 286, 148, 201, 273, 210, 177, 75, 270, 298, 284, 26, 20, 271, 67, 132, 119, 184, 253, 8, 35, 280, 212, 104, 211, 50, 134, 31, 108, 149, 101, 82, 272, 176, 58, 219, 14, 240, 115, 206, 28, 54, 121, 76, 172, 29, 103, 269, 19, 27, 163], 'papers_amount': 90}, '2': {'papers_ids': [196, 237, 230, 254, 242, 80, 299, 279, 53, 250, 289, 248, 217, 9, 195, 48, 185, 2, 15, 37, 151, 153, 239, 165, 13, 168, 113, 170, 23, 6, 205, 236, 39, 57, 127, 3, 283, 135, 198, 215, 59, 181, 112, 169, 49, 98, 116, 100, 213, 238, 216, 0, 93, 91, 223, 47, 218, 183, 142, 179], 'papers_amount': 60}, '3': {'papers_ids': [193, 22, 21, 123, 81, 226, 61, 265, 171, 12, 145, 4, 147, 275, 120, 74, 263, 232, 166, 77, 293, 278, 68, 200, 109, 92, 194, 107, 160, 222, 247, 55, 16, 86, 51, 62, 25, 256, 11, 40, 235, 45, 208, 73, 255, 136, 66, 84, 267, 42, 164, 131, 63, 274, 5, 246, 122, 87, 290, 44, 173, 234, 85, 249, 52, 38, 117, 266, 192, 111, 56, 97, 187, 259, 202, 207, 88, 243, 34, 285, 244, 32, 110, 186, 90, 89, 252, 180, 229, 130], 'papers_amount': 90}, '4': {'papers_ids': [296, 137, 118, 69, 288, 245, 102, 24, 140, 128, 295, 106, 225, 154, 30, 1, 294, 204, 146, 43, 105, 191, 268, 70, 95, 174, 197, 297, 79, 189, 41, 94, 7, 291, 251, 114, 214, 228, 46, 199, 99, 64, 281, 126, 72], 'papers_amount': 45}}\n---------- PAPER DISTRIBUTIONS GENERATION COMPLETED ----------\n"
     ],
     "output_type": "stream"
    }
   ],
   "source": [
    "# ------------------------------\n",
    "# ---- CORE IMPLEMENTATION -----\n",
    "# ------------------------------\n",
    "\n",
    "# Papers distribution generation with beta distribution\n",
    "\n",
    "print(\"---------- PAPER DISTRIBUTIONS GENERATION STARTED ----------\")\n",
    "\n",
    "generated_configurations = {\"0\":{},\"1\":{},\"2\":{},\"3\":{},\"4\":{}}\n",
    "\n",
    "beta_distributions_frequencies = [(0, int(round((5*papers_number/100))))]\n",
    "beta_distributions_frequencies.append((1, int(round(30*papers_number/100))))\n",
    "beta_distributions_frequencies.append((2, int(round(20*papers_number/100))))\n",
    "beta_distributions_frequencies.append((3, int(round(30*papers_number/100))))\n",
    "beta_distributions_frequencies.append((4, int(round(15*papers_number/100))))\n",
    "\n",
    "papers_set = set(papers)\n",
    "paper_distributions = [None] * papers_number\n",
    "\n",
    "generated_papers_distributions = 0\n",
    "for (index, papers_amount) in beta_distributions_frequencies:\n",
    "    current_paper_set = rn.sample(papers_set, papers_amount)\n",
    "    generated_configurations[\"{}\".format(index)][\"papers_ids\"] = current_paper_set\n",
    "    generated_configurations[\"{}\".format(index)][\"papers_amount\"] = papers_amount\n",
    "    for paper in current_paper_set:\n",
    "        a = 0\n",
    "        b = 0\n",
    "        if index==0:\n",
    "            # CASE 1: a == b == 1, 5% of papers\n",
    "            a = 1\n",
    "            b = 1\n",
    "        if index==1:\n",
    "            # CASE 2: a == b > 1, 30% of papers\n",
    "            a = rn.randint(2, 10)\n",
    "            b = a\n",
    "        if index == 2:\n",
    "            # CASE 3: 0 < (a ^ b) < 1, 30% of papers\n",
    "            a = rn.uniform(0.001, 1)\n",
    "            b = rn.uniform(0.001, 1)\n",
    "        if index == 3:\n",
    "            # CASE 4: (a V b) == 1, (a > b V b > a), 20% of papers\n",
    "            a = 1\n",
    "            b = rn.randint(1, 10)\n",
    "            if rn.randint(0,1) > 0.5:\n",
    "                a, b = b, a\n",
    "        if index == 4:\n",
    "            # CASE 5: (a ^ b) > 1, (a > b V b > a), 15% of papers\n",
    "            a = rn.randint(2, 10)\n",
    "            b = rn.randint(2 + a, 10 + a)\n",
    "            if rn.randint(0,1) > 0.5:\n",
    "                a, b = b, a\n",
    "        percentage = 100*generated_papers_distributions/papers_number\n",
    "        if percentage % 10 == 0:\n",
    "            print(\"{}/{} ({}/100%)\".format(int(generated_papers_distributions), papers_number, int(percentage)))\n",
    "        paper_distributions[paper] = [a, b]\n",
    "        generated_papers_distributions = generated_papers_distributions + 1\n",
    "        papers_set.remove(paper)\n",
    "print(\"{}/{} (100/100%)\".format(papers_number, papers_number))\n",
    "\n",
    "print(generated_configurations)\n",
    "\n",
    "print(\"---------- PAPER DISTRIBUTIONS GENERATION COMPLETED ----------\")"
   ],
   "metadata": {
    "pycharm": {
     "metadata": false,
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "outputs": [
    {
     "name": "stdout",
     "text": [
      "---------- READERS SETS GENERATION STARTED ----------\nSET 0: [881 983   1 219 475 227  65  38 832   8 421 565 144 137 522 981 939 563\n  92 982 464 378 585  96 987  36  18 805 967 289 210 821 459  81 356 466\n 591 674 493 577 410 679 296 665 803 142 998  93 263 584 163 153 511 770\n 668 225 460 106  53 437 288 718 936 365 415 132 854 792 535 377 932 209\n 918 568 237 204 148 518  66 814 973 473 543 608  62 871 315 516 505 240\n 116 971 127 471 865 686 903 303 720 416 454 173 215 310   4 885 603 648\n 806 659  35 555 654  33 521 947 332 726 699 196 552 299 757 771  48 530\n 779 791 879 155 525 811 878  88  13 486 432 159 863  44  67 943 520 722\n 891 693 260 691 450 907 257  86 358 503 733 861 304 551 860 412 948 927\n 710 717 103 624 834 850 478  95 502 244 130 445 264 135 114 769 508 269\n 664 797 905 892 405 681 550 250 636 950 828 847 276 965  52 425 734 239\n 208 202]\nSET 1: [539 640 381 169 123 976 533 940 126 465 637  70 802 194 233 515 598 800\n 223 427  47 176 685  23 616 945 942 186  74 178 293 449 474 545 167 479\n 217 920 744 160 282 384 426 549 147  73 337 235  59  24 989 183 968  14\n 302 615 631 672 177 642 788 110 328 953 281 652 714 316 848 923 404 868\n  58 124 831 606 756  76 538 441 199 889 980  37 683 924 986 897 740 583\n 495 929 417 541 253 179 913 678 816 735 957 571 150 750 564 727 729 845\n 813  45 580  25 882 985 259 760 963 855 218 919 348 611 306 463 934 181\n 440 207 795   2  72 312 862 712 930  16 625 230 825 249 529 448 490 597\n 933  39 901 472 273 857 837 350 387 581 984 256 883 499 420 651  19 252\n 534 131 351 859 748 398 595 569 872 955 104 149 220 978  21 695 172 650\n  98 866 820 928 228 504 990 327 423 754 341 660 317 483 354 347 205 345\n 342 484]\nSET 2: [212 768 762 285 319 158  89 238 916 245 655 899 270 570  29 776 999 108\n 966 272 610 162 494 896 914 623 826 361 979 383 812 380 146 506 401 340\n 702 254 514 638  57 278 817 630 620 785  17 395 793 621 960 371 334 856\n 374 221  79 430 938 759 593 704 322 661 635 993 482 226 675 557 133 671\n 926 290 841 641 402 884 211 129 787 527  49 790 414 397 895 195 532 589\n 122 991 956 389 970 893 846 346 852 140  50 604 373 941 627 673 409 470\n  87 524 436 438 353  68 808 200 382  43 424  75  63 739 152 143  28 829\n 125 267 741 154 324 182 864 236 725 553 646 964 251 128 117  85 708 622\n 458 599 745 724 352 333 390 798 255 161 141 323 751 836 969 428 643 102\n 476 921 313 858 367 489 120 853 286 283 801 480 839 810 988 265 363 764\n 229 619 667 975  20 596 909 175 241 498 509 443 111 309 709 875 189 600\n 780 732]\nSET 3: [ 34 789 917  78  60 874 399 972 157 587 222 731 766 308 455 634 977 992\n 822 698 258 609 461 898 684 694 867 375 422 197  64 782 413 248 174 198\n 349 835 647 360 321 411 138 357 331 833 369 558 937 778 851 904 368 393\n 869 784 469  51 628 477   6 191  40 231 180 100  83  91 723 908 335 974\n  69 761 692 271 279 336 559  94 954 554 338 796 809 676 540  82 912 758\n 946 601 819 696 206 298 877 602 962 268 400 330 728 359 716 452 526 911\n 743 662 481 284 703 185 531 291 287 900 562 574 485 118 618 818 370 994\n 444 386 224   3 711 134  27 318 706 403 468 807  41 188 364  46 355 305\n 746 394 329 890  55 507 931 605 830   9 190 910 261 775 996 166 457 311\n  80 429 339 656 247 561 105 280 843 689 453 645 842 677 767 961  22 781\n 542 873 730 560 500 737   0 935 633 277 752 216 307 151 838 497 763 773\n 170 294]\nSET 4: [492 572 136 794 669  11 274 171 713 888 431 952  10 573 719 396 772 193\n 101 566 164 343 246 824 326 501 876 266 314 870 902 385 658 582  84 292\n 456 906 774 827  56  99 925 783 613 439 536 701 275 592  32 958 844 213\n 644 451  42 109 187 663 649 243 682 372 519 300 548 418 297 184 262 434\n 670 523  26 715 753 301 886 629 119 747 721 959 491 922 379 894 944 617\n 657 391 546 567 156 586 406 214 594 799 700 325 517 556 112 786   5 366\n 590 887 738 705 537 680 165 435 544 433 376 242  31 344 362 192 487 742\n 997 115 736 528 320 392 765   7 697 407 107  71 612 408 815 201 849 576\n  15 632 653 488 840 578 626 607 510 579 462 804 145 512 690 547 121 995\n 755 949 496 168 614 666 688 951 687 113 447 777 232 588 234 139 575  12\n 823  54  90 880 446 419 442 467  97 203 388  77 707 295 513  30 915 749\n 639  61]\n---------- READERS SETS GENERATION COMPLETED ----------\n---------- RATINGS GENERATION STARTED ----------\n0/10000 (0/100%)\n",
      "1000/10000 (10/100%)\n",
      "2000/10000 (20/100%)\n",
      "3000/10000 (30/100%)\n",
      "4000/10000 (40/100%)\n5000/10000 (50/100%)\n",
      "6000/10000 (60/100%)\n",
      "7000/10000 (70/100%)\n",
      "8000/10000 (80/100%)\n9000/10000 (90/100%)\n",
      "10000/10000 (100/100%)\n---------- RATINGS GENERATION ENDED ----------\n"
     ],
     "output_type": "stream"
    }
   ],
   "source": [
    "# Ratings file generation\n",
    "\n",
    "# N sets of readers, each one has X% of the total\n",
    "\n",
    "readers_percent = 20\n",
    "reader_sets_number = m.floor(100 / readers_percent)\n",
    "readers_amount = m.floor((readers_number*readers_percent)/100)\n",
    "\n",
    "readers_sets = []\n",
    "\n",
    "# Readers rate papers with a certain frequency\n",
    "\n",
    "print(\"---------- READERS SETS GENERATION STARTED ----------\")\n",
    "\n",
    "ratings_number = sum(paper_frequencies) * readers_amount\n",
    "\n",
    "for x in range(0, reader_sets_number):\n",
    "    current_readers_set = np.random.choice(readers, readers_amount, False) \n",
    "    readers = np.setdiff1d(readers, current_readers_set)\n",
    "    readers_sets.append(current_readers_set)\n",
    "    print(\"SET {}: {}\".format(x, current_readers_set))\n",
    "\n",
    "print(\"---------- READERS SETS GENERATION COMPLETED ----------\")\n",
    "\n",
    "print(\"---------- RATINGS GENERATION STARTED ----------\")\n",
    "\n",
    "generated_ratings = 0\n",
    "rated_papers = []\n",
    "with open(ratings_file_path, mode='w', newline='') as ratings_file:\n",
    "    ratings_writer = csv.writer(ratings_file, delimiter=',', quotechar='\"', quoting=csv.QUOTE_MINIMAL)\n",
    "    ratings_writer.writerow(['Timestamp', 'Reader', 'Paper', 'Score'])\n",
    "    for current_set in range(0, reader_sets_number):\n",
    "        frequency = paper_frequencies[current_set]\n",
    "        readers_set = readers_sets[current_set]\n",
    "        for reader in readers_set:\n",
    "            sample = np.random.choice(papers, frequency, False)     \n",
    "            for paper in sample:    \n",
    "                paper_distribution = beta(paper_distributions[paper][0],paper_distributions[paper][1])\n",
    "                percentage = 100*generated_ratings/ratings_number\n",
    "                if percentage % 10 == 0:\n",
    "                    print(\"{}/{} ({}/100%)\".format(int(generated_ratings), ratings_number, int(percentage)))\n",
    "                generated_rating = round(paper_distribution.rvs(1)[0], 2)\n",
    "                if generated_rating == 0:\n",
    "                    generated_rating = 0.01\n",
    "                ratings_writer.writerow([\n",
    "                    generated_ratings, \n",
    "                    reader, \n",
    "                    paper, \n",
    "                    generated_rating\n",
    "                ])\n",
    "                rated_papers.append(paper)\n",
    "                generated_ratings+=1\n",
    "    \n",
    "    # Filling gaps\n",
    "    readers = np.arange(readers_number)\n",
    "    unrated_papers = set(papers) - set(rated_papers)    \n",
    "    for paper in unrated_papers:\n",
    "        for reader in np.random.choice(readers, 5, False):\n",
    "            paper_distribution = paper_distributions[paper]\n",
    "            generated_rating = round(paper_distribution.rvs(1)[0], 2)\n",
    "            if generated_rating == 0:\n",
    "                generated_rating = 0.01\n",
    "                ratings_writer.writerow([\n",
    "                    generated_ratings, \n",
    "                    reader, \n",
    "                    paper,\n",
    "                    generated_rating\n",
    "                ])\n",
    "                generated_ratings+=1\n",
    "        \n",
    "    print(\"{}/{} (100/100%)\".format(ratings_number, ratings_number))\n",
    "    \n",
    "ratings_file.close()\n",
    "\n",
    "paper_ratings = pd.read_csv(ratings_file_path)\n",
    "paper_ratings = paper_ratings.sample(frac=1)\n",
    "paper_ratings[\"Timestamp\"] = range(len(paper_ratings))\n",
    "paper_ratings.reset_index(drop=True, inplace=True)\n",
    "\n",
    "paper_ratings.to_csv(ratings_file_path, index=False, header=True, sep=\",\")\n",
    "\n",
    "print(\"---------- RATINGS GENERATION ENDED ----------\")"
   ],
   "metadata": {
    "pycharm": {
     "metadata": false,
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "outputs": [
    {
     "name": "stdout",
     "text": [
      "---------- AUTHORS GENERATION STARTED ----------\n0/40 (0/100%)\n4/40 (10/100%)\n8/40 (20/100%)\n12/40 (30/100%)\n16/40 (40/100%)\n20/40 (50/100%)\n24/40 (60/100%)\n28/40 (70/100%)\n32/40 (80/100%)\n36/40 (90/100%)\n40/40 (100/100%)\n---------- AUTHORS GENERATION ENDED ----------\n"
     ],
     "output_type": "stream"
    }
   ],
   "source": [
    "# Authors file generation\n",
    "\n",
    "print(\"---------- AUTHORS GENERATION STARTED ----------\")\n",
    "\n",
    "with open(authors_file_path, mode='w', newline='') as authors_file:\n",
    "    authors_writer = csv.writer(authors_file, delimiter=',', quotechar='\"', quoting=csv.QUOTE_MINIMAL)\n",
    "    authors_writer.writerow([\"Author\", \"Paper\"])\n",
    "    for index, author in enumerate(authors):\n",
    "        percentage = 100*index/authors_number\n",
    "        if percentage % 10 == 0:\n",
    "            print(\"{}/{} ({}/100%)\".format(int(index), authors_number, int(percentage)))\n",
    "        # An author writes a number of paper between 1 and paper_fraction\n",
    "        author_papers_number = rn.randint(1, (papers_number-1))\n",
    "        papers_written = np.random.choice(papers, author_papers_number).tolist()\n",
    "        papers_written = set(papers_written)\n",
    "        if len(papers_written) > 1:\n",
    "            papers_written = map(str, list(papers_written))\n",
    "            papers_written = \";\".join(papers_written)\n",
    "        else:\n",
    "            papers_written = list(papers_written)[0]\n",
    "        authors_writer.writerow([author, papers_written])\n",
    "    print(\"{}/{} (100/100%)\".format(authors_number, authors_number))\n",
    "authors_file.close()\n",
    "        \n",
    "print(\"---------- AUTHORS GENERATION ENDED ----------\")"
   ],
   "metadata": {
    "pycharm": {
     "metadata": false,
     "name": "#%% \n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "outputs": [
    {
     "name": "stdout",
     "text": [
      "---------- INFO GENERATION STARTED ----------\n---------- INFO GENERATION ENDED ----------\n"
     ],
     "output_type": "stream"
    }
   ],
   "source": [
    "# Info file generation\n",
    "\n",
    "print(\"---------- INFO GENERATION STARTED ----------\")\n",
    "\n",
    "info_dataframe = pd.DataFrame(columns=[\"Dataset\", \"Paper\", \"Reader\", \"Rating\", \"Author\"])\n",
    "info_dataframe = info_dataframe.append(\n",
    "    {\n",
    "        \"Dataset\": dataset_name, \n",
    "        \"Paper\": papers_number, \n",
    "        \"Reader\": readers_number, \n",
    "        \"Rating\": ratings_number, \n",
    "        \"Author\": authors_number\n",
    "    }, ignore_index=True)\n",
    "info_dataframe.to_csv(info_file_path, index=False)\n",
    "\n",
    "print(\"---------- INFO GENERATION ENDED ----------\")"
   ],
   "metadata": {
    "pycharm": {
     "metadata": false,
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "outputs": [
    {
     "name": "stdout",
     "text": [
      "---------- STATS GENERATION STARTED ----------\n---------- COMPUTING STATS FOR PAPERS ----------\n---------- COMPUTING STATS FOR READERS ----------",
      "\n---------- STATS GENERATION COMPLETED ----------\n"
     ],
     "output_type": "stream"
    }
   ],
   "source": [
    "# Stats file generation\n",
    "\n",
    "print(\"---------- STATS GENERATION STARTED ----------\")\n",
    "\n",
    "temp_ratings_dataframe = pd.read_csv(ratings_file_path)\n",
    "temp_ratings_dataframe[temp_ratings_dataframe.columns] = temp_ratings_dataframe[temp_ratings_dataframe.columns].apply(pd.to_numeric)\n",
    "\n",
    "stats_dataframe = temp_ratings_dataframe.copy()\n",
    "stats_dataframe[stats_dataframe > 0.0000001] = 1\n",
    "\n",
    "print(\"---------- COMPUTING STATS FOR PAPERS ----------\")\n",
    "\n",
    "sums_paper = stats_dataframe.copy().sum(axis=0)\n",
    "sums_paper_dataframe = pd.DataFrame(sums_paper)\n",
    "\n",
    "max_ratings_paper = sums_paper_dataframe.max()\n",
    "min_ratings_paper = sums_paper_dataframe.min()\n",
    "mean_ratings_paper = sums_paper_dataframe.mean()\n",
    "\n",
    "temp_ratings_dataframe = temp_ratings_dataframe.T\n",
    "paper_counter = 0\n",
    "for index, row in temp_ratings_dataframe.iterrows():\n",
    "    if len(np.unique(row)) == 1:\n",
    "        paper_counter+=1\n",
    "        \n",
    "print(\"---------- COMPUTING STATS FOR READERS ----------\")\n",
    "\n",
    "sums_reader = stats_dataframe.copy().sum(axis=1)\n",
    "counter=collections.Counter(sums_reader)\n",
    "sums_reader_dataframe = pd.DataFrame(sums_reader)\n",
    "\n",
    "max_ratings_reader = sums_reader_dataframe.max()\n",
    "min_ratings_reader = sums_reader_dataframe.min()\n",
    "mean_ratings_reader = sums_reader_dataframe.mean()\n",
    "\n",
    "temp_ratings_dataframe = temp_ratings_dataframe\n",
    "reader_counter = 0\n",
    "for index, row in temp_ratings_dataframe.iterrows():\n",
    "    if len(np.unique(row)) == 1:\n",
    "        reader_counter+=1\n",
    "        \n",
    "# Writing stats to file\n",
    "\n",
    "stats_dataframe = pd.DataFrame(columns=[\n",
    "    \"Dataset\",\n",
    "    \"Max Number Rating Paper\", \n",
    "    \"Min Number Rating Paper\", \n",
    "    \"Mean Number Rating Paper\",\n",
    "    \"Number Papers Unique Ratings\",\n",
    "    \"Max Number Rating Reader\", \n",
    "    \"Min Number Rating Reader\", \n",
    "    \"Mean Number Rating Reader\"\n",
    "    \"Number Readers Unique Rating\"\n",
    "])\n",
    "stats_dataframe = stats_dataframe.append(\n",
    "    {\n",
    "        \"Dataset\": dataset_name, \n",
    "        \"Max Number Rating Paper\": int(max_ratings_paper.values[0]), \n",
    "        \"Min Number Rating Paper\": int(min_ratings_paper.values[0]), \n",
    "        \"Number Papers Unique Ratings\": paper_counter, \n",
    "        \"Mean Number Rating Paper\": int(mean_ratings_paper.values[0]), \n",
    "        \"Max Number Rating Reader\": int(max_ratings_reader.values[0]), \n",
    "        \"Min Number Rating Reader\": int(min_ratings_reader.values[0]), \n",
    "        \"Mean Number Rating Reader\": int(mean_ratings_reader.values[0]), \n",
    "        \"Number Readers Unique Rating\": reader_counter, \n",
    "    }, ignore_index=True)\n",
    "stats_dataframe.to_csv(stats_file_path, index=False)\n",
    "\n",
    "print(\"---------- STATS GENERATION COMPLETED ----------\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "outputs": [
    {
     "name": "stdout",
     "text": [
      "---------- SPECIAL RATINGS STARTED ----------\n[10000, 'SR#1000', 86, 0.7167323083334484]\n[10001, 'SR#1001', 86, 0]\n[10002, 'SR#1002', 86, 0.3583661541667242]\n[10003, 'SR#1000', 170, 0.6609600592353534]\n[10004, 'SR#1001', 170, 0]\n[10005, 'SR#1002', 170, 0.3304800296176767]\n[10006, 'SR#1000', 157, 0.29535888423234624]\n[10007, 'SR#1001', 157, 0]\n[10008, 'SR#1002', 157, 0.3523205578838269]\n[10009, 'SR#1000', 74, 0.5885145167386845]\n[10010, 'SR#1001', 74, 0]\n[10011, 'SR#1002', 74, 0.29425725836934224]\n[10012, 'SR#1000', 71, 0.5435082779430089]\n[10013, 'SR#1001', 71, 0]\n[10014, 'SR#1002', 71, 0.27175413897150447]\n[10015, 'SR#1000', 149, 0.5989233144910766]\n[10016, 'SR#1001', 149, 0]\n[10017, 'SR#1002', 149, 0.2994616572455383]\n[10018, 'SR#1000', 162, 0.42659919983721595]\n[10019, 'SR#1001', 162, 0]\n[10020, 'SR#1002', 162, 0.286700400081392]\n[10021, 'SR#1000', 221, 0.3667721972620214]\n[10022, 'SR#1001', 221, 0]\n[10023, 'SR#1002', 221, 0.31661390136898926]\n[10024, 'SR#1000', 197, 0.4727196997227238]\n[10025, 'SR#1001', 197, 0]\n[10026, 'SR#1002', 197, 0.26364015013863806]\n[10027, 'SR#1000', 163, 0.8017713337163908]\n[10028, 'SR#1001', 163, 0]\n[10029, 'SR#1002', 163, 0.4008856668581954]\n[10030, 'SR#1000', 276, 0.9937357621339022]\n[10031, 'SR#1001', 276, 0]\n[10032, 'SR#1002', 276, 0.4968678810669511]\n[10033, 'SR#1000', 16, 0.06726331598633312]\n[10034, 'SR#1001', 16, 0]\n[10035, 'SR#1002', 16, 0.4663683420068334]\n[10036, 'SR#1000', 97, 0.8999822828412198]\n[10037, 'SR#1001', 97, 0]\n[10038, 'SR#1002', 97, 0.4499911414206099]\n[10039, 'SR#1000', 119, 0.310251400158752]\n[10040, 'SR#1001', 119, 0]\n[10041, 'SR#1002', 119, 0.344874299920624]\n[10042, 'SR#1000', 194, 0.6996466123938198]\n[10043, 'SR#1001', 194, 0]\n[10044, 'SR#1002', 194, 0.3498233061969099]\n[10045, 'SR#1000', 8, 0.8957749777656482]\n[10046, 'SR#1001', 8, 0]\n[10047, 'SR#1002', 8, 0.4478874888828241]\n[10048, 'SR#1000', 46, 0.13064661357720606]\n[10049, 'SR#1001', 46, 0]\n[10050, 'SR#1002', 46, 0.43467669321139696]\n[10051, 'SR#1000', 206, 0.7161783325248828]\n[10052, 'SR#1001', 206, 0]\n[10053, 'SR#1002', 206, 0.3580891662624414]\n[10054, 'SR#1000', 51, 0.5114182806765349]\n[10055, 'SR#1001', 51, 0]\n[10056, 'SR#1002', 51, 0.25570914033826747]\n[10057, 'SR#1000', 249, 0.5693217261477382]\n[10058, 'SR#1001', 249, 0]\n[10059, 'SR#1002', 249, 0.2846608630738691]\n[10060, 'SR#1000', 192, 0.42980146227766425]\n[10061, 'SR#1001', 192, 0]\n[10062, 'SR#1002', 192, 0.2850992688611679]\n[10063, 'SR#1000', 270, 0.8340339213374639]\n[10064, 'SR#1001', 270, 0]\n[10065, 'SR#1002', 270, 0.41701696066873195]\n[10066, 'SR#1000', 92, 0.15911524875543684]\n[10067, 'SR#1001', 92, 0]\n[10068, 'SR#1002', 92, 0.4204423756222816]\n[10069, 'SR#1000', 225, 0.3835608751632335]\n[10070, 'SR#1001', 225, 0]\n[10071, 'SR#1002', 225, 0.3082195624183832]\n[10072, 'SR#1000', 173, 0.8349029425835797]\n[10073, 'SR#1001', 173, 0]\n[10074, 'SR#1002', 173, 0.41745147129178983]\n[10075, 'SR#1000', 263, 0.3783235155617965]\n[10076, 'SR#1001', 263, 0]\n[10077, 'SR#1002', 263, 0.3108382422191017]\n[10078, 'SR#1000', 207, 0.6142605773749247]\n[10079, 'SR#1001', 207, 0]\n[10080, 'SR#1002', 207, 0.30713028868746234]\n[10081, 'SR#1000', 222, 0.7794238594525613]\n[10082, 'SR#1001', 222, 0]\n[10083, 'SR#1002', 222, 0.38971192972628066]\n[10084, 'SR#1000', 50, 0.8150609884471883]\n[10085, 'SR#1001', 50, 0]\n[10086, 'SR#1002', 50, 0.40753049422359416]\n[10087, 'SR#1000', 30, 0.23667803052073644]\n[10088, 'SR#1001', 30, 0]\n[10089, 'SR#1002', 30, 0.3816609847396318]\n[10090, 'SR#1000', 146, 0.9177775359910155]\n[10091, 'SR#1001', 146, 0]\n[10092, 'SR#1002', 146, 0.45888876799550776]\n[10093, 'SR#1000', 132, 0.752860707201012]\n[10094, 'SR#1001', 132, 0]\n[10095, 'SR#1002', 132, 0.376430353600506]\n[10096, 'SR#1000', 79, 0.7384348422923662]\n[10097, 'SR#1001', 79, 0]\n[10098, 'SR#1002', 79, 0.3692174211461831]\n[10099, 'SR#1000', 61, 0.2625734946697984]\n[10100, 'SR#1001', 61, 0]\n[10101, 'SR#1002', 61, 0.3687132526651008]\n[10102, 'SR#1000', 282, 0.7236943324647229]\n[10103, 'SR#1001', 282, 0]\n[10104, 'SR#1002', 282, 0.36184716623236146]\n[10105, 'SR#1000', 120, 0.37734919135170336]\n[10106, 'SR#1001', 120, 0]\n[10107, 'SR#1002', 120, 0.31132540432414835]\n[10108, 'SR#1000', 178, 0.5759612069126394]\n[10109, 'SR#1001', 178, 0]\n[10110, 'SR#1002', 178, 0.2879806034563197]\n[10111, 'SR#1000', 238, 0.4573274164319882]\n[10112, 'SR#1001', 238, 0]\n[10113, 'SR#1002', 238, 0.27133629178400587]\n[10114, 'SR#1000', 200, 0.3682682547896959]\n[10115, 'SR#1001', 200, 0]\n[10116, 'SR#1002', 200, 0.3158658726051521]\n[10117, 'SR#1000', 143, 0.5670209938066989]\n[10118, 'SR#1001', 143, 0]\n[10119, 'SR#1002', 143, 0.28351049690334945]\n[10120, 'SR#1000', 107, 0.4397616735156732]\n[10121, 'SR#1001', 107, 0]\n[10122, 'SR#1002', 107, 0.2801191632421634]\n[10123, 'SR#1000', 262, 0.06315132702846056]\n[10124, 'SR#1001', 262, 0]\n[10125, 'SR#1002', 262, 0.4684243364857697]\n[10126, 'SR#1000', 290, 0.5020111087475408]\n[10127, 'SR#1001', 290, 0]\n[10128, 'SR#1002', 290, 0.2510055543737704]\n[10129, 'SR#1000', 85, 0.5486039149099765]\n[10130, 'SR#1001', 85, 0]\n[10131, 'SR#1002', 85, 0.27430195745498825]\n[10132, 'SR#1000', 134, 0.26367660958061684]\n[10133, 'SR#1001', 134, 0]\n[10134, 'SR#1002', 134, 0.36816169520969155]\n[10135, 'SR#1000', 199, 0.024224512737141178]\n[10136, 'SR#1001', 199, 0]\n[10137, 'SR#1002', 199, 0.4878877436314294]\n[10138, 'SR#1000', 177, 0.992796780046068]\n[10139, 'SR#1001', 177, 0]\n[10140, 'SR#1002', 177, 0.496398390023034]\n[10141, 'SR#1000', 29, 0.5055909037427718]\n[10142, 'SR#1001', 29, 0]\n[10143, 'SR#1002', 29, 0.2527954518713859]\n[10144, 'SR#1000', 166, 0.9106561600007718]\n[10145, 'SR#1001', 166, 0]\n[10146, 'SR#1002', 166, 0.4553280800003859]\n[10147, 'SR#1000', 148, 0.8450029883321275]\n[10148, 'SR#1001', 148, 0]\n[10149, 'SR#1002', 148, 0.42250149416606375]\n[10150, 'SR#1000', 63, 0.1217195119029342]\n[10151, 'SR#1001', 63, 0]\n[10152, 'SR#1002', 63, 0.4391402440485329]\n[10153, 'SR#1000', 145, 0.7714218435132287]\n[10154, 'SR#1001', 145, 0]\n[10155, 'SR#1002', 145, 0.38571092175661437]\n[10156, 'SR#1000', 267, 0.553374003256403]\n[10157, 'SR#1001', 267, 0]\n[10158, 'SR#1002', 267, 0.2766870016282015]\n[10159, 'SR#1000', 265, 0.34280310854949503]\n[10160, 'SR#1001', 265, 0]\n[10161, 'SR#1002', 265, 0.3285984457252525]\n[10162, 'SR#1000', 228, 0.5193311098777617]\n[10163, 'SR#1001', 228, 0]\n[10164, 'SR#1002', 228, 0.2596655549388808]\n[10165, 'SR#1000', 175, 0.947638177251849]\n[10166, 'SR#1001', 175, 0]\n[10167, 'SR#1002', 175, 0.4738190886259245]\n[10168, 'SR#1000', 116, 0.33746932342156183]\n[10169, 'SR#1001', 116, 0]\n[10170, 'SR#1002', 116, 0.3312653382892191]\n[10171, 'SR#1000', 52, 0.2515669815458904]\n[10172, 'SR#1001', 52, 0]\n[10173, 'SR#1002', 52, 0.3742165092270548]\n[10174, 'SR#1000', 17, 0.4058449695251252]\n[10175, 'SR#1001', 17, 0]\n[10176, 'SR#1002', 17, 0.2970775152374374]\n[10177, 'SR#1000', 291, 0.49004839075784795]\n[10178, 'SR#1001', 291, 0]\n[10179, 'SR#1002', 291, 0.25497580462107605]\n---------- SPECIAL RATINGS COMPLETED  ----------\n"
     ],
     "output_type": "stream"
    }
   ],
   "source": [
    "# Data generation for experiments\n",
    "\n",
    "# ------------------------------\n",
    "# -- EXP 1-A: DATA GENERATION --\n",
    "# ------------------------------\n",
    "\n",
    "print(\"---------- SPECIAL RATINGS STARTED ----------\")\n",
    "\n",
    "gaussian_beta_distributions = generated_configurations[\"2\"]\n",
    "papers_identifiers = gaussian_beta_distributions[\"papers_ids\"]\n",
    "for paper in papers_identifiers:\n",
    "    mean = (paper_distributions[paper][0]/(paper_distributions[paper][0] + paper_distributions[paper][1]))\n",
    "    SR1_rating_id = generated_ratings\n",
    "    SR1_reader = \"SR#{}\".format(readers_number)\n",
    "    SR1_paper = paper\n",
    "    SR1_rating_score = mean\n",
    "    SR2_rating_id = generated_ratings+1\n",
    "    SR2_reader = \"SR#{}\".format(readers_number+1)\n",
    "    SR2_paper = paper\n",
    "    SR3_rating_id = generated_ratings+2\n",
    "    SR3_reader = \"SR#{}\".format(readers_number+2)\n",
    "    SR3_paper = paper\n",
    "    if mean <= 0.5:\n",
    "        SR2_rating_score = 0\n",
    "        SR3_rating_score = (1-mean)/2\n",
    "    else:\n",
    "        SR2_rating_score = 0\n",
    "        SR3_rating_score = mean/2\n",
    "    #print([SR1_rating_id, SR1_reader, SR1_paper, SR1_rating_score])\n",
    "    #print([SR2_rating_id, SR2_reader, SR2_paper, SR2_rating_score])\n",
    "    #print([SR3_rating_id, SR3_reader, SR3_paper, SR3_rating_score])\n",
    "    generated_ratings = generated_ratings + 3\n",
    "\n",
    "print(\"---------- SPECIAL RATINGS COMPLETED  ----------\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# ------------------------------\n",
    "# -- EXP 1-B: DATA GENERATION --\n",
    "# ------------------------------\n",
    "\n",
    "print(\"---------- RATINGS SHUFFLING STARTED ----------\")\n",
    "\n",
    "if shuffling:\n",
    "    os.makedirs(dataset_shuffle_folder_path, exist_ok=True)\n",
    "    for s in range(shuffle_number):\n",
    "        c = 0\n",
    "        if s % 10 == 0:\n",
    "            print(\"{}/{} ({}/100%)\".format(s, shuffle_number, s))\n",
    "        current_shuffle_file_path = \"{}/shuffle_{}.csv\".format(dataset_shuffle_folder_path, s)\n",
    "        shuffled_papers_ratings = paper_ratings.sample(frac=1)\n",
    "        for i, row in shuffled_papers_ratings.iterrows():\n",
    "            shuffled_papers_ratings.at[i,'Timestamp'] = c\n",
    "            c  = c + 1\n",
    "        shuffled_papers_ratings.to_csv(current_shuffle_file_path, index=False, header=True, sep=\",\")\n",
    "    print(\"{}/{} (100/100%)\".format(shuffle_number, shuffle_number))\n",
    "    \n",
    "print(\"---------- RATINGS SHUFFLING COMPLETED ----------\")\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "python3",
   "language": "python",
   "display_name": "Python 3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  },
  "pycharm": {
   "stem_cell": {
    "cell_type": "raw",
    "source": [],
    "metadata": {
     "collapsed": false
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}